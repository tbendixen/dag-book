[["index.html", "The Data Analyst’s Guide to Cause and Effect Companion website Welcome! Version Errata", " The Data Analyst’s Guide to Cause and Effect Companion website Theiss Bendixen &amp; Benjamin Grant Purzycki 2024-12-28 Welcome! The is the companion website for The Data Analyst’s Guide to Cause and Effect (Bendixen &amp; Purzycki, in prep.). Data and code for this e-book is hosted at https://github.com/tbendixen/dag-book. Version This is version 0.1 Errata While we have made every effort to ensure the accuracy and currency of both the book and this website, some errors may have inevitably slipped through. In this section, we will document any errors or updates as they are brought to our attention. If you spot an error, please reach out to tb@theissbendixen.com "],["chapter-1.html", "Chapter 1 Introduction", " Chapter 1 Introduction Placeholder. "],["chapter-2.html", "Chapter 2 Causal Graphs 2.1 The Fork 2.2 The Pipe 2.3 The Collider 2.4 Post-treatment bias 2.5 Session info", " Chapter 2 Causal Graphs 2.1 The Fork We first simulate some data from the simple ‘Fork’ DAG. set.seed(1747) n &lt;- 1e4 bZ &lt;- 1 Z &lt;- rnorm(n, 0, 1) X &lt;- Z*bZ + rnorm(n, 0, 1) Y &lt;- Z*bZ + rnorm(n, 0, 1) We then write a function for fitting and plotting our models that we can re-use for the ‘Pipe’ and ‘Collider’ scenarios. This function depends on the ggplot2 and patchwork (Pedersen 2024) packages. library(ggplot2) library(patchwork) plot_scat &lt;- function(data, title){ # Y ~ X p1 &lt;- ggplot(data, aes(x=X, y=Y)) + geom_point(alpha = 0.05, size = .1) + geom_smooth(method=&#39;lm&#39;, color = &quot;blue&quot;, linewidth = 0.5) + theme_classic() + labs(title = title, subtitle = &quot;Y ~ X&quot;) # Y ~ X + Z model &lt;- lm(Y ~ X + Z, data = data) new_data &lt;- transform(data, Z = 0) predictions &lt;- predict(model, newdata = new_data, interval = &quot;confidence&quot;) p2 &lt;- ggplot(data, aes(x = X, y = Y)) + geom_point(alpha = 0.05, size = .1) + geom_line(data = new_data, aes(y = predictions[, &quot;fit&quot;]), linewidth = 0.5, color = &quot;blue&quot;) + geom_ribbon(data = new_data, aes(ymin = predictions[, &quot;lwr&quot;], ymax = predictions[, &quot;upr&quot;]), alpha = 0.2) + theme_classic() + labs(subtitle = &quot;Y ~ X + Z&quot;) return(p1 + p2) } We then apply the function to the simulated data. plot_scat(data = data.frame(Y=Y, X=X, Z=Z), title = &quot;The Fork&quot;) 2.2 The Pipe Similarly to above, we simulate data from the ‘Pipe’ DAG… set.seed(1747) n &lt;- 1e4 bZ &lt;- 1 bX &lt;- 1 X &lt;- rnorm(n, 0, 1) Z &lt;- X*bX + rnorm(n, 0, 1) Y &lt;- Z*bZ + rnorm(n, 0, 1) … and then apply our custom fitting and plotting function. plot_scat(data = data.frame(Y=Y, X=X, Z=Z), title = &quot;The Pipe&quot;) 2.3 The Collider Exactly the same approach as above. set.seed(1747) n &lt;- 1e4 bX &lt;- 1 bY &lt;- 1 X &lt;- rnorm(n, 0, 1) Y &lt;- rnorm(n, 0, 1) Z &lt;- X*bX + Y*bY + rnorm(n, 0, 1) plot_scat(data = data.frame(Y=Y, X=X, Z=Z), title = &quot;The Collider&quot;) 2.4 Post-treatment bias Again, following the same approach, we simulate data from the post-treatment DAG. set.seed(1747) n &lt;- 1e4 bZ &lt;- 1 bX &lt;- 0.5 bY &lt;- 1 Z &lt;- rnorm(n, 0, 1) X &lt;- Z*bZ + rnorm(n, 0, 1) Y &lt;- Z*bZ + X*bX + rnorm(n, 0, 1) P &lt;- Y*bY + rnorm(n, 0, 1) Next, we fit two models: One that adjusts for the post-treatment variable P… glm(Y ~ X + Z + P, data = data.frame(Y=Y, X=X, Z=Z, P=P)) ## ## Call: glm(formula = Y ~ X + Z + P, data = data.frame(Y = Y, X = X, ## Z = Z, P = P)) ## ## Coefficients: ## (Intercept) X Z P ## 0.01018 0.25354 0.50133 0.48813 ## ## Degrees of Freedom: 9999 Total (i.e. Null); 9996 Residual ## Null Deviance: 34040 ## Residual Deviance: 4895 AIC: 21240 … and another that doesn’t. glm(Y ~ X + Z, data = data.frame(Y=Y, X=X, Z=Z)) ## ## Call: glm(formula = Y ~ X + Z, data = data.frame(Y = Y, X = X, Z = Z)) ## ## Coefficients: ## (Intercept) X Z ## 0.007601 0.495594 0.987202 ## ## Degrees of Freedom: 9999 Total (i.e. Null); 9997 Residual ## Null Deviance: 34040 ## Residual Deviance: 9793 AIC: 28180 We see that only the latter model picks up the correct estimate for X, which was 0.5 in this case. 2.5 Session info sessionInfo() ## R version 4.4.0 (2024-04-24 ucrt) ## Platform: x86_64-w64-mingw32/x64 ## Running under: Windows 10 x64 (build 19045) ## ## Matrix products: default ## ## ## locale: ## [1] LC_COLLATE=Danish_Denmark.utf8 LC_CTYPE=Danish_Denmark.utf8 ## [3] LC_MONETARY=Danish_Denmark.utf8 LC_NUMERIC=C ## [5] LC_TIME=Danish_Denmark.utf8 ## ## time zone: Europe/Copenhagen ## tzcode source: internal ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] patchwork_1.2.0 ggplot2_3.5.1 ## ## loaded via a namespace (and not attached): ## [1] Matrix_1.7-0 gtable_0.3.5 jsonlite_1.8.8 highr_0.11 ## [5] dplyr_1.1.4 compiler_4.4.0 tidyselect_1.2.1 jquerylib_0.1.4 ## [9] splines_4.4.0 scales_1.3.0 yaml_2.3.8 fastmap_1.2.0 ## [13] lattice_0.22-6 R6_2.5.1 labeling_0.4.3 generics_0.1.3 ## [17] knitr_1.47 tibble_3.2.1 bookdown_0.39 munsell_0.5.1 ## [21] bslib_0.7.0 pillar_1.9.0 rlang_1.1.3 utf8_1.2.4 ## [25] cachem_1.1.0 xfun_0.44 sass_0.4.9 cli_3.6.2 ## [29] withr_3.0.0 magrittr_2.0.3 mgcv_1.9-1 digest_0.6.35 ## [33] grid_4.4.0 rstudioapi_0.16.0 lifecycle_1.0.4 nlme_3.1-164 ## [37] vctrs_0.6.5 evaluate_0.23 glue_1.7.0 farver_2.1.2 ## [41] fansi_1.0.6 colorspace_2.1-0 rmarkdown_2.27 tools_4.4.0 ## [45] pkgconfig_2.0.3 htmltools_0.5.8.1 References Pedersen, Thomas Lin. 2024. patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork. "],["chapter-3.html", "Chapter 3 G-methods and Marginal Effects 3.1 Inverse probability weighting 3.2 G-computation 3.3 Session info", " Chapter 3 G-methods and Marginal Effects 3.1 Inverse probability weighting For our illustration of IPW and g-computation, we simulate some simple confounded data. set.seed(1747) n &lt;- 1e4 bZ &lt;- 2 bX &lt;- 2 Z &lt;- rnorm(n, 0, 0.5) X &lt;- rbinom(n, 1, plogis(0.5 + Z*bZ)) Y &lt;- rnorm(n, 10 + X*bX + Z*bZ) d &lt;- data.frame(Y=Y, X=X, Z=Z) For IPW, we first fit a logistic regression model of the probability of receiving treatment. treatment_model &lt;- glm(X ~ Z, data = d, family = &quot;binomial&quot;) We then predict for each individual their probability of receiving treatment. d$pX &lt;- predict(treatment_model, type = &quot;response&quot;) Lastly, we inverse those probabilities and use them as weights in a model – a so-called ‘marginal structural model’ – that regresses Y on X. d$w &lt;- with(d, ifelse(X==1, 1/pX, 1/(1-pX))) lm(Y ~ X, data = d, weights = w) We then compare the treatment (solid lines) and control (dashed lines) groups before (i.e., in the observed sample) and after weighting (i.e., the IPW ‘pseudo-population’). # IPW with unstabilized weights library(ggplot2) library(patchwork) p1 &lt;- ggplot() + # X = 1 (sample) geom_density(data = subset(d, X == 1), aes(x = pX), size = 1) + # X = 0 (sample) geom_density(data = subset(d, X == 0), aes(x = pX), linetype = &quot;dashed&quot;, size = 1) + theme_classic() + theme( axis.text.y = element_blank(), axis.ticks.y = element_blank(), axis.title.y = element_blank(), axis.line.y = element_blank()) + xlim(c(0,1)) + xlab(&quot;Probability of treatment&quot;) + ggtitle(&quot;Before IP weighting&quot;) p2 &lt;- ggplot() + # X = 1 (pseudo-population) geom_density(data = subset(d, X == 1), aes(x = pX, weight = w), size = 1) + # X = 0 (pseudo-population) geom_density(data = subset(d, X == 0), aes(x = pX, weight = w), linetype = &quot;dashed&quot;, size = 1) + theme_classic() + theme( axis.text.y = element_blank(), axis.ticks.y = element_blank(), axis.title.y = element_blank(), axis.line.y = element_blank()) + xlim(c(0,1)) + xlab(&quot;Probability of treatment&quot;) + ggtitle(&quot;After IP weighting&quot;) (p1 + p2) The above approach showcases IPW with so-called ‘unstabilized’ weights. But stabilizing the IP weights are often recommended. Stabilized weights uses an unconditional model for the treatment probability instead of 1 as the numerator in the IPW formula. Let’s visualize this wit the stabilized weights plotted with a dashed curve. We see that the stabilized weights are much less extreme. # IPW with stabilized weights pn &lt;- glm(X ~ 1, data = d, family = &quot;binomial&quot;) d$pnX &lt;- predict(pn, type = &quot;response&quot;) d$sw &lt;- with(d, ifelse(X==1, pnX/pX, (1-pnX)/(1-pX))) p3 &lt;- ggplot() + geom_density(data = d, aes(x = w), size = 1) + geom_density(data = d, aes(x = sw), linetype = &quot;dashed&quot;, size = 1) + theme_classic() + theme_classic() + theme( axis.text.y = element_blank(), axis.ticks.y = element_blank(), axis.title.y = element_blank(), axis.line.y = element_blank()) + xlab(&quot;IP weight&quot;) + coord_cartesian(xlim = c(0,10)) + labs(title = &quot;Unstabilized and stabilized weights&quot;) p3 3.1.1 Bootstrapping Here’s a basic bootstrapping approach for IPW. We use only 100 bootstrap samples, but in practice we’d often want (many) more. # Load necessary libraries library(boot) # Number of bootstrap samples n_bootstrap &lt;- 100 # Function to perform the analysis on a bootstrapped sample bootstrap_analysis &lt;- function(data, indices) { # Resample the data d &lt;- data[indices, ] # Fit the treatment model using logistic regression treatment_model &lt;- glm(X ~ Z, data = d, family = &quot;binomial&quot;) # Calculate predicted probabilities d$pX &lt;- predict(treatment_model, type = &quot;response&quot;) # Calculate weights d$w &lt;- with(d, ifelse(X == 1, 1 / pX, 1 / (1 - pX))) # Fit the weighted linear regression model weighted_model &lt;- lm(Y ~ X, data = d, weights = w) # Return the coefficient of X return(coef(weighted_model)[&quot;X&quot;]) } # Perform bootstrapping bootstrap_results &lt;- boot(data = d, statistic = bootstrap_analysis, R = n_bootstrap) # Summarize the bootstrap results bootstrap_summary &lt;- boot.ci(bootstrap_results, type = &quot;norm&quot;) # Print the results print(bootstrap_summary) ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 100 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = bootstrap_results, type = &quot;norm&quot;) ## ## Intervals : ## Level Normal ## 95% ( 1.946, 2.057 ) ## Calculations and Intervals on Original Scale 3.1.2 ‘Robust’ standard errors for IPW library(sandwich) # robust standard errors for coefficients fit &lt;- lm(Y ~ X, data = d, weights = w) vcovHC(fit, type = &#39;HC0&#39;) ## (Intercept) X ## (Intercept) 0.001036983 -0.001036983 ## X -0.001036983 0.001564404 3.2 G-computation Here, we show a basic g-computation workflow… model &lt;- lm(Y ~ X + Z, data = d) d$EX1 &lt;- predict(model, newdata = transform(d, X = 1)) d$EX0 &lt;- predict(model, newdata = transform(d, X = 0)) with(d, mean(EX1)-mean(EX0)) … And code to produce the table showing both observed and predicted values, some of which are counter-factual. vars &lt;- c(&quot;Y&quot;, &quot;X&quot;, &quot;Z&quot;, &quot;EX1&quot;, &quot;EX0&quot;) xtable::xtable(head(d[vars]), digits = c(0,1,0,1,1,1)) ## % latex table generated in R 4.4.0 by xtable 1.8-4 package ## % Sat Dec 28 21:33:20 2024 ## \\begin{table}[ht] ## \\centering ## \\begin{tabular}{rrrrrr} ## \\hline ## &amp; Y &amp; X &amp; Z &amp; EX1 &amp; EX0 \\\\ ## \\hline ## 1 &amp; 15.3 &amp; 1 &amp; 0.6 &amp; 13.2 &amp; 11.2 \\\\ ## 2 &amp; 11.1 &amp; 0 &amp; 0.1 &amp; 12.2 &amp; 10.2 \\\\ ## 3 &amp; 10.6 &amp; 1 &amp; -0.1 &amp; 11.7 &amp; 9.7 \\\\ ## 4 &amp; 12.9 &amp; 1 &amp; 0.7 &amp; 13.4 &amp; 11.3 \\\\ ## 5 &amp; 11.0 &amp; 1 &amp; -0.5 &amp; 10.9 &amp; 8.9 \\\\ ## 6 &amp; 9.4 &amp; 0 &amp; 0.5 &amp; 12.9 &amp; 10.9 \\\\ ## \\hline ## \\end{tabular} ## \\end{table} 3.2.1 Bootstrapping Next, we show a basic bootstrapped g-computation implementation, again using only 100 bootstrap samples to ease the computational burden of the example. # Number of bootstrap samples n_bootstrap &lt;- 100 # Define the function to perform the analysis on a bootstrapped sample bootstrap_analysis &lt;- function(data, indices) { # Resample the data d &lt;- data[indices, ] # Fit the linear regression model model &lt;- lm(Y ~ X + Z, data = d) # Calculate predicted values for X = 1 and X = 0 d$EX1 &lt;- predict(model, newdata = transform(d, X = 1)) d$EX0 &lt;- predict(model, newdata = transform(d, X = 0)) # Compute the difference in means ate &lt;- with(d, mean(EX1) - mean(EX0)) return(ate) } # Perform bootstrapping bootstrap_results &lt;- boot(data = d, statistic = bootstrap_analysis, R = n_bootstrap) # Summarize the bootstrap results bootstrap_summary &lt;- boot.ci(bootstrap_results, type = c(&quot;norm&quot;)) # Print the results print(bootstrap_summary) ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 100 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = bootstrap_results, type = c(&quot;norm&quot;)) ## ## Intervals : ## Level Normal ## 95% ( 1.962, 2.050 ) ## Calculations and Intervals on Original Scale 3.2.2 Bayesian g-computation Lastly, we show a Bayesian g-computation workflow using the R package brms (Bürkner 2017, 2018, 2021), which requires RStan (Stan Development Team 2024), for model fitting and tidybayes for post-processing (Kay 2023). library(brms) library(tidybayes) library(dplyr) # Fit Bayesian regression bmodel &lt;- brm(Y ~ X + Z, data = d, cores = 4, seed = 1, file = &quot;fits/bmodel.rds&quot;) # Calculate predicted values for X = 1 and X = 0 bEX1 &lt;- add_epred_draws(object = bmodel, newdata = transform(d, X = 1)) bEX0 &lt;- add_epred_draws(object = bmodel, newdata = transform(d, X = 0)) The key thing to note when working with Bayesian model fits is that we need to calculate our quantity of interest (here, the ATE) within each posterior draw. # Compute the difference in means ate &lt;- data.frame(EX1 = bEX1$.epred, EX0 = bEX0$.epred, draw = bEX0$.draw) |&gt; # For each posterior draw... group_by(draw) |&gt; # ... Calculate ATE summarise(ate = mean(EX1 - EX0)) We can summarize the posterior ATE by its mean and highest posterior density interval. mean_hdi(ate$ate) ## y ymin ymax .width .point .interval ## 1 2.009257 1.964355 2.051421 0.95 mean hdi An alternative approach – when we have a fitted model, Bayesian or otherwise – is via the versatile and very well documented marginaleffects package (Arel-Bundock, Greifer, and Heiss Forthcoming). library(marginaleffects) avg_comparisons(bmodel, variables = list(X = 0:1)) ## Error: cannot allocate vector of size 610.4 Mb 3.3 Session info sessionInfo() ## R version 4.4.0 (2024-04-24 ucrt) ## Platform: x86_64-w64-mingw32/x64 ## Running under: Windows 10 x64 (build 19045) ## ## Matrix products: default ## ## ## locale: ## [1] LC_COLLATE=Danish_Denmark.utf8 LC_CTYPE=Danish_Denmark.utf8 ## [3] LC_MONETARY=Danish_Denmark.utf8 LC_NUMERIC=C ## [5] LC_TIME=Danish_Denmark.utf8 ## ## time zone: Europe/Copenhagen ## tzcode source: internal ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] sandwich_3.1-0 patchwork_1.2.0 ggplot2_3.5.1 ## ## loaded via a namespace (and not attached): ## [1] gtable_0.3.5 tensorA_0.36.2.1 xfun_0.44 ## [4] bslib_0.7.0 QuickJSR_1.1.3 inline_0.3.19 ## [7] lattice_0.22-6 vctrs_0.6.5 tools_4.4.0 ## [10] generics_0.1.3 stats4_4.4.0 parallel_4.4.0 ## [13] tibble_3.2.1 fansi_1.0.6 highr_0.11 ## [16] pkgconfig_2.0.3 brms_2.21.0 Matrix_1.7-0 ## [19] checkmate_2.3.1 distributional_0.4.0 RcppParallel_5.1.7 ## [22] lifecycle_1.0.4 compiler_4.4.0 farver_2.1.2 ## [25] stringr_1.5.1 Brobdingnag_1.2-9 munsell_0.5.1 ## [28] codetools_0.2-20 htmltools_0.5.8.1 sass_0.4.9 ## [31] bayesplot_1.11.1 yaml_2.3.8 pillar_1.9.0 ## [34] jquerylib_0.1.4 cachem_1.1.0 StanHeaders_2.32.9 ## [37] bridgesampling_1.1-2 abind_1.4-5 nlme_3.1-164 ## [40] posterior_1.5.0 rstan_2.32.6 tidyselect_1.2.1 ## [43] digest_0.6.35 mvtnorm_1.2-5 stringi_1.8.4 ## [46] dplyr_1.1.4 bookdown_0.39 labeling_0.4.3 ## [49] splines_4.4.0 fastmap_1.2.0 grid_4.4.0 ## [52] colorspace_2.1-0 cli_3.6.2 magrittr_2.0.3 ## [55] loo_2.7.0 pkgbuild_1.4.4 utf8_1.2.4 ## [58] withr_3.0.0 scales_1.3.0 backports_1.5.0 ## [61] estimability_1.5.1 rmarkdown_2.27 matrixStats_1.3.0 ## [64] emmeans_1.10.4 gridExtra_2.3 zoo_1.8-12 ## [67] coda_0.19-4.1 evaluate_0.23 knitr_1.47 ## [70] mgcv_1.9-1 rstantools_2.4.0 rlang_1.1.3 ## [73] Rcpp_1.0.12 xtable_1.8-4 glue_1.7.0 ## [76] rstudioapi_0.16.0 jsonlite_1.8.8 R6_2.5.1 References Arel-Bundock, Vincent, Noah Greifer, and Andrew Heiss. Forthcoming. “How to Interpret Statistical Models Using marginaleffects in R and Python.” Journal of Statistical Software, Forthcoming. Bürkner, Paul-Christian. 2017. “brms: An R Package for Bayesian Multilevel Models Using Stan.” Journal of Statistical Software 80 (1): 1–28. https://doi.org/10.18637/jss.v080.i01. ———. 2018. “Advanced Bayesian Multilevel Modeling with the R Package brms.” The R Journal 10 (1): 395–411. https://doi.org/10.32614/RJ-2018-017. ———. 2021. “Bayesian Item Response Modeling in R with brms and Stan.” Journal of Statistical Software 100 (5): 1–54. https://doi.org/10.18637/jss.v100.i05. Kay, Matthew. 2023. tidybayes: Tidy Data and Geoms for Bayesian Models. https://doi.org/10.5281/zenodo.1308151. ———. 2024. “RStan: The R Interface to Stan.” https://mc-stan.org/. "],["chapter-4.html", "Chapter 4 Adventures in G-methods 4.1 Doubly robust estimation 4.2 Bootstrapped sub-group analysis 4.3 Complex longitudinal designs 4.4 More complexity 4.5 Session info", " Chapter 4 Adventures in G-methods 4.1 Doubly robust estimation For demonstrating a ‘doubly robust’ estimator that combines IPW and g-computation, we use the nhefs data from the causaldata package (Huntington-Klein and Barrett 2021). This data come from the National Health and Nutrition Examination Survey Data I Epidemiologic Follow-up Study. library(causaldata) d &lt;- nhefs We first calculate stabilized IP weights. treat_mod &lt;- glm(qsmk ~ sex + age, data = d, family = &quot;binomial&quot;) d$pX &lt;- predict(treat_mod, type = &quot;response&quot;) pn &lt;- glm(qsmk ~ 1, data = d, family = &quot;binomial&quot;) d$pnX &lt;- predict(pn, type = &quot;response&quot;) d$sw &lt;- with(d, ifelse(qsmk==1, pnX/pX, (1-pnX)/(1-pX))) We can then plot the sample before and after weighting. library(ggplot2) library(patchwork) p1 &lt;- ggplot() + # X = 1 (sample) geom_density(data = subset(d, qsmk == 1), aes(x = pX), size = 1) + # X = 0 (sample) geom_density(data = subset(d, qsmk == 0), aes(x = pX), linetype = &quot;dashed&quot;, size = 1) + theme_classic() + theme( axis.text.y = element_blank(), axis.ticks.y = element_blank(), axis.title.y = element_blank(), axis.line.y = element_blank()) + xlim(c(0,1)) + xlab(&quot;Probability of treatment&quot;) + ggtitle(&quot;Before IP weighting&quot;) p2 &lt;- ggplot() + # X = 1 (pseudo-population) geom_density(data = subset(d, qsmk == 1), aes(x = pX, weight = sw), size = 1) + # X = 0 (pseudo-population) geom_density(data = subset(d, qsmk == 0), aes(x = pX, weight = sw), linetype = &quot;dashed&quot;, size = 1) + theme_classic() + theme( axis.text.y = element_blank(), axis.ticks.y = element_blank(), axis.title.y = element_blank(), axis.line.y = element_blank()) + xlim(c(0,1)) + xlab(&quot;Probability of treatment&quot;) + ggtitle(&quot;After IP weighting&quot;) (p1 + p2) We can also make a ‘love plot’ using the cobalt package (Greifer 2024) to inspect whether the IP weights ensures acceptable balance on the level of individual covariates. By setting continuous = \"std\", we indicate that the function should return the standardized absolute mean difference for any continuous variables (here, age). If we wanted the raw absolute mean difference, we’d set continuous = \"raw\". library(cobalt) love.plot(treat_mod, abs = TRUE, sample.names = c(&quot;Unweighted&quot;, &quot;IP Weighted&quot;), weights = d$sw, colors = c(&quot;grey60&quot;, &quot;black&quot;), thresholds = c(m = .1)) bal.tab(treat_mod, abs = TRUE, un = TRUE, thresholds = c(m = .1), weights = d$sw, continuous = &quot;std&quot;)$Balance Finally, we include the stabilized weights in an outcome model, which we in turn use for g-computation. out_mod &lt;- lm(wt82_71 ~ qsmk + sex + age, data = d, weights = sw) EX1 &lt;- predict(out_mod, newdata = transform(d, qsmk = 1)) EX0 &lt;- predict(out_mod, newdata = transform(d, qsmk = 0)) mean(EX1)-mean(EX0) ## [1] 3.039286 4.1.1 Bootstrapping The basic approach to bootstrapping is similar as in the previous chapter. Here, we bootstrap the doubly robust estimator from above. We use only 100 bootstrap samples, but in practice we’d often want more. library(boot) # Number of bootstrap samples n_bootstrap &lt;- 100 bootstrap_analysis &lt;- function(data, indices) { # Resample the data d &lt;- data[indices, ] # IPW treat_mod &lt;- glm(qsmk ~ sex + age, data = d, family = &quot;binomial&quot;) d$pX &lt;- predict(treat_mod, type = &quot;response&quot;) pn &lt;- glm(qsmk ~ 1, data = d, family = &quot;binomial&quot;) d$pnX &lt;- predict(pn, type = &quot;response&quot;) d$sw &lt;- with(d, ifelse(qsmk==1, pnX/pX, (1-pnX)/(1-pX))) # G-computation with IP weighted outcome model out_mod &lt;- lm(wt82_71 ~ qsmk + sex + age, data = d, weights = sw) EX1 &lt;- predict(out_mod, newdata = transform(d, qsmk = 1)) EX0 &lt;- predict(out_mod, newdata = transform(d, qsmk = 0)) mean(EX1)-mean(EX0) # Return the coefficient of X return(mean(EX1)-mean(EX0)) } # Perform bootstrapping bootstrap_results &lt;- boot(data = d, statistic = bootstrap_analysis, R = n_bootstrap) # Summarize the bootstrap results bootstrap_summary &lt;- boot.ci(bootstrap_results, type = &quot;norm&quot;) # Print the results print(bootstrap_summary) ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 100 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = bootstrap_results, type = &quot;norm&quot;) ## ## Intervals : ## Level Normal ## 95% ( 2.092, 3.909 ) ## Calculations and Intervals on Original Scale 4.1.2 More covariates We can try the same analysis but with a more comprehensive set of covariates. library(boot) bootstrap_analysis &lt;- function(data, indices) { # Resample the data d &lt;- data[indices, ] # IPW # see: https://remlapmot.github.io/cibookex-r/ip-weighting-and-marginal-structural-models.html treat_mod &lt;- glm(qsmk ~ sex + race + age + I(age ^ 2) + as.factor(education) + smokeintensity + I(smokeintensity ^ 2) + smokeyrs + I(smokeyrs ^ 2) + as.factor(exercise) + as.factor(active) + wt71 + I(wt71 ^ 2), data = d, family = &quot;binomial&quot;) d$pX &lt;- predict(treat_mod, type = &quot;response&quot;) pn &lt;- glm(qsmk ~ 1, data = d, family = &quot;binomial&quot;) d$pnX &lt;- predict(pn, type = &quot;response&quot;) d$sw &lt;- with(d, ifelse(qsmk==1, pnX/pX, (1-pnX)/(1-pX))) # G-computation with IP weighted outcome model out_mod &lt;- lm(wt82_71 ~ qsmk + sex + race + age + I(age ^ 2) + as.factor(education) + smokeintensity + I(smokeintensity ^ 2) + smokeyrs + I(smokeyrs ^ 2) + as.factor(exercise) + as.factor(active) + wt71 + I(wt71 ^ 2), data = d, weights = sw) EX1 &lt;- predict(out_mod, newdata = transform(d, qsmk = 1)) EX0 &lt;- predict(out_mod, newdata = transform(d, qsmk = 0)) mean(EX1)-mean(EX0) # Return the coefficient of X return(mean(EX1)-mean(EX0)) } # Perform bootstrapping bootstrap_results &lt;- boot(data = d, statistic = bootstrap_analysis, R = n_bootstrap) # Summarize the bootstrap results bootstrap_summary &lt;- boot.ci(bootstrap_results, type = &quot;norm&quot;) # Print the results print(bootstrap_summary) ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 100 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = bootstrap_results, type = &quot;norm&quot;) ## ## Intervals : ## Level Normal ## 95% ( 2.620, 4.393 ) ## Calculations and Intervals on Original Scale The overall inference is the same, although the more comprehensive adjustment set yields a slightly higher point estimate (around 3.5 kg), indicating that quitters gain even more weight than previously estimated. 4.2 Bootstrapped sub-group analysis bootstrap_analysis &lt;- function(data, indices) { # Resample the data d &lt;- data[indices, ] # IPW pn_sub &lt;- glm(qsmk ~ 1 + sex, data = d, family = &quot;binomial&quot;) d$pnX &lt;- predict(pn_sub, type = &quot;response&quot;) d$sw &lt;- with(d, ifelse(qsmk == 1, pnX / pX, (1 - pnX) / (1 - pX))) # G-computation with IP weighted outcome model out_mod &lt;- glm(wt82_71 ~ qsmk + sex + age + qsmk * sex, data = d, weights = sw) EX1S1 &lt;- predict(out_mod, newdata = transform(d, qsmk = 1, sex = as.factor(1))) EX1S0 &lt;- predict(out_mod, newdata = transform(d, qsmk = 1, sex = as.factor(0))) EX0S1 &lt;- predict(out_mod, newdata = transform(d, qsmk = 0, sex = as.factor(1))) EX0S0 &lt;- predict(out_mod, newdata = transform(d, qsmk = 0, sex = as.factor(0))) mean_diff_S1 &lt;- mean(EX1S1) - mean(EX0S1) mean_diff_S0 &lt;- mean(EX1S0) - mean(EX0S0) return(c(mean_diff_S1, mean_diff_S0)) } # Perform bootstrapping bootstrap_results &lt;- boot(data = d, statistic = bootstrap_analysis, R = n_bootstrap) # Extract and display results boot.ci(bootstrap_results, type = &quot;norm&quot;, index = 1) # For females ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 100 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = bootstrap_results, type = &quot;norm&quot;, index = 1) ## ## Intervals : ## Level Normal ## 95% ( 1.619, 4.043 ) ## Calculations and Intervals on Original Scale boot.ci(bootstrap_results, type = &quot;norm&quot;, index = 2) # For males ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 100 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = bootstrap_results, type = &quot;norm&quot;, index = 2) ## ## Intervals : ## Level Normal ## 95% ( 2.291, 4.585 ) ## Calculations and Intervals on Original Scale 4.3 Complex longitudinal designs In the book, we walk through a g-computation approach to a complex longitudinal data context with a time-varying treatment. Here, we show a stabilized IPW approach. The trick is to compute two sets of weights, one for each time point and adjustment set. These weights can then be combined with multiplication in a single marginal structural model that recovers the simulated true effects of 0. set.seed(1747) n &lt;- 1e4 U &lt;- rnorm(n, 0, 1) Z_0 &lt;- rbinom(n, 1, plogis(0.5)) X_0 &lt;- rbinom(n, 1, plogis(0.5 + Z_0 * 0.5)) Z_1 &lt;- rbinom(n, 1, plogis(0.5 + X_0 * 0.5 + U * 0.5)) X_1 &lt;- rbinom(n, 1, plogis(0.5 + Z_1 * 0.5)) Y &lt;- rnorm(n, 10 + U * 2) dat &lt;- data.frame(Y = Y, X_0 = X_0, X_1 = X_1, Z_0 = Z_0, Z_1 = Z_1, U = U) # IPW estimation for X_0 # Fit propensity score model (denominator) ps_model_X0 &lt;- glm(X_0 ~ Z_0 + X_1, family = &quot;binomial&quot;, data = dat) dat$ps_X0 &lt;- predict(ps_model_X0, type = &quot;response&quot;) # Fit numerator model num_model_X0 &lt;- glm(X_0 ~ Z_0, family = &quot;binomial&quot;, data = dat) dat$num_ps_X0 &lt;- predict(num_model_X0, type = &quot;response&quot;) # Calculate stabilized weights dat$sw_X0 &lt;- with(dat, ifelse(X_0 == 1, num_ps_X0/ps_X0, (1-num_ps_X0)/(1-ps_X0))) # IPW estimation for X_1 # Fit propensity score model (denominator) ps_model_X1 &lt;- glm(X_1 ~ X_0 + Z_1, family = &quot;binomial&quot;, data = dat) dat$ps_X1 &lt;- predict(ps_model_X1, type = &quot;response&quot;) # Fit numerator model num_model_X1 &lt;- glm(X_1 ~ X_0, family = &quot;binomial&quot;, data = dat) dat$num_ps_X1 &lt;- predict(num_model_X1, type = &quot;response&quot;) # Calculate stabilized weights dat$sw_X1 &lt;- with(dat, ifelse(X_1 == 1, num_ps_X1/ps_X1, (1-num_ps_X1)/(1-ps_X1))) # Marginal structural model lm(Y ~ X_0 + X_1, data = dat, weights = sw_X0*sw_X1) ## ## Call: ## lm(formula = Y ~ X_0 + X_1, data = dat, weights = sw_X0 * sw_X1) ## ## Coefficients: ## (Intercept) X_0 X_1 ## 10.009573 -0.039207 0.007237 4.4 More complexity In the book, we show a complicated DAG adapted from VanderWeele, Jackson, and Li (2016) of a complex longitudinal exposure-outcome feedback setting. Here, we verify that the adjustment strategy suggested in the book holds true in a simulated setting. While in this particular simulated example the model coefficients for X1, X2 and X3 in their respective focal models coincide with the marginal estimates we’re after, we want to practice a more general workflow for when it really matters. So, we both show a g-computation approach and a stabilized IPW approach. First, we simulate some data consistent with the complex DAG. # Seed for reproducibility set.seed(42) # Define sample size n &lt;- 1e4 # Simulate time-varying relationships C &lt;- rnorm(n) Z1 &lt;- rnorm(n, C) + rnorm(n) X1 &lt;- rbinom(n, 1, plogis(C + rnorm(n))) X2 &lt;- rbinom(n, 1, plogis(C + X1 + Z1 + rnorm(n))) Z2 &lt;- rnorm(n, C + Z1 + X1) + rnorm(n) X3 &lt;- rbinom(n, 1, plogis(C + X2 + Z2 + rnorm(n))) Z3 &lt;- rnorm(n, C + Z2 + X2) + rnorm(n) # Simulate outcome Y &lt;- X1 + X2 + X3 + Z3 + C + rnorm(n) # Create dataset d &lt;- data.frame(C, Z1, Z2, Z3, X1, X2, X3, Y) Next, we fit a model for each measurement time point, and we see that all three models pick up the true effects within simulation error. The true effects are 2, 2 and 1, respectively, for the three time points. It’s 2 for the first two time points, because these effects include paths running through Z2/Z3. 4.4.1 G-computation There are no new tricks here compared to what we showcase in the book, except we’re breaking down our joint effect estimand into separate models. # Model to estimate effect of X1 on Y model_X1 &lt;- glm(Y ~ X1 + X2 + Z1 + C, data = d) EX11 &lt;- predict(model_X1, newdata = transform(d, X1 = 1)) EX10 &lt;- predict(model_X1, newdata = transform(d, X1 = 0)) mean(EX11 - EX10) ## [1] 2.083152 # Model to estimate effect of X2 on Y model_X2 &lt;- lm(Y ~ X1 + X2 + X3 + Z1 + Z2 + C, data = d) EX21 &lt;- predict(model_X2, newdata = transform(d, X2 = 1)) EX20 &lt;- predict(model_X2, newdata = transform(d, X2 = 0)) mean(EX21 - EX20) ## [1] 1.988808 # Model to estimate effect of X3 on Y model_X3 &lt;- lm(Y ~ X2 + X3 + Z2 + C, data = d) EX31 &lt;- predict(model_X3, newdata = transform(d, X3 = 1)) EX30 &lt;- predict(model_X3, newdata = transform(d, X3 = 0)) mean(EX31 - EX30) ## [1] 0.9987202 4.4.2 IPW We follow the same recipe for stabilized IPW as given in the book. # IPW estimation for X1 # Fit propensity score model (denominator) ps_model_X1 &lt;- glm(X1 ~ C + X2 + Z1, family = &quot;binomial&quot;, data = d) d$ps_X1 &lt;- predict(ps_model_X1, type = &quot;response&quot;) # Fit numerator model num_model_X1 &lt;- glm(X1 ~ C, family = &quot;binomial&quot;, data = d) d$num_ps_X1 &lt;- predict(num_model_X1, type = &quot;response&quot;) # Calculate stabilized weights d$sw_X1 &lt;- with(d, ifelse(X1 == 1, num_ps_X1/ps_X1, (1-num_ps_X1)/(1-ps_X1))) # Marginal structural model lm(Y ~ X1 + C, data = d, weights = sw_X1) ## ## Call: ## lm(formula = Y ~ X1 + C, data = d, weights = sw_X1) ## ## Coefficients: ## (Intercept) X1 C ## 1.663 2.091 4.831 # IPW estimation for X2 # Fit propensity score model (denominator) ps_model_X2 &lt;- glm(X2 ~ X1 + X3 + Z1 + Z2 + C, family = &quot;binomial&quot;, data = d) d$ps_X2 &lt;- predict(ps_model_X2, type = &quot;response&quot;) # Fit numerator model num_model_X2 &lt;- glm(X2 ~ C, family = &quot;binomial&quot;, data = d) d$num_ps_X2 &lt;- predict(num_model_X2, type = &quot;response&quot;) # Calculate stabilized weights d$sw_X2 &lt;- with(d, ifelse(X2 == 1, num_ps_X2/ps_X2, (1-num_ps_X2)/(1-ps_X2))) # Marginal structural model lm(Y ~ X2 + C, data = d, weights = sw_X2) ## ## Call: ## lm(formula = Y ~ X2 + C, data = d, weights = sw_X2) ## ## Coefficients: ## (Intercept) X2 C ## 1.549 2.108 4.645 # IPW estimation for X3 # Fit propensity score model (denominator) ps_model_X3 &lt;- glm(X3 ~ X2 + Z2 + C, family = &quot;binomial&quot;, data = d) d$ps_X3 &lt;- predict(ps_model_X3, type = &quot;response&quot;) # Fit numerator model num_model_X3 &lt;- glm(X3 ~ C, family = &quot;binomial&quot;, data = d) d$num_ps_X3 &lt;- predict(num_model_X3, type = &quot;response&quot;) # Calculate stabilized weights d$sw_X3 &lt;- with(d, ifelse(X3 == 1, num_ps_X3/ps_X3, (1-num_ps_X3)/(1-ps_X3))) # Marginal structural model lm(Y ~ X3 + Z3 + C, data = d, weights = sw_X3) ## ## Call: ## lm(formula = Y ~ X3 + Z3 + C, data = d, weights = sw_X3) ## ## Coefficients: ## (Intercept) X3 Z3 C ## 0.8849 1.0250 1.1221 0.9908 Instead of fitting a marginal structural model (MSM) for each time point, we can fit a single MSM for all three time points in one go. The trick here is to multiply the weights. However, this targets a slightly different estimand, since we want to adjust for Z3 to get a more precise estimate for X3 but including Z3 in the MSM blocks the the effect of X1 and X2 that runs through Z3. That is, this alternative specification targets only the direct effect of the exposures. lm(Y ~ X1 + X2 + X3 + Z3 + C, data = d, weights = sw_X1*sw_X2*sw_X3) ## ## Call: ## lm(formula = Y ~ X1 + X2 + X3 + Z3 + C, data = d, weights = sw_X1 * ## sw_X2 * sw_X3) ## ## Coefficients: ## (Intercept) X1 X2 X3 Z3 C ## -0.01181 0.99327 0.98364 1.00694 1.00863 0.96940 For further details on estimating time-varying relationships with IPW, see VanderWeele, Jackson, and Li (2016). 4.5 Session info sessionInfo() ## R version 4.4.0 (2024-04-24 ucrt) ## Platform: x86_64-w64-mingw32/x64 ## Running under: Windows 10 x64 (build 19045) ## ## Matrix products: default ## ## ## locale: ## [1] LC_COLLATE=Danish_Denmark.utf8 LC_CTYPE=Danish_Denmark.utf8 ## [3] LC_MONETARY=Danish_Denmark.utf8 LC_NUMERIC=C ## [5] LC_TIME=Danish_Denmark.utf8 ## ## time zone: Europe/Copenhagen ## tzcode source: internal ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] cobalt_4.5.5 causaldata_0.1.3 sandwich_3.1-0 patchwork_1.2.0 ## [5] ggplot2_3.5.1 ## ## loaded via a namespace (and not attached): ## [1] gtable_0.3.5 tensorA_0.36.2.1 xfun_0.44 ## [4] bslib_0.7.0 QuickJSR_1.1.3 inline_0.3.19 ## [7] lattice_0.22-6 vctrs_0.6.5 tools_4.4.0 ## [10] generics_0.1.3 stats4_4.4.0 parallel_4.4.0 ## [13] tibble_3.2.1 fansi_1.0.6 highr_0.11 ## [16] pkgconfig_2.0.3 brms_2.21.0 Matrix_1.7-0 ## [19] checkmate_2.3.1 distributional_0.4.0 RcppParallel_5.1.7 ## [22] lifecycle_1.0.4 compiler_4.4.0 farver_2.1.2 ## [25] stringr_1.5.1 Brobdingnag_1.2-9 munsell_0.5.1 ## [28] codetools_0.2-20 htmltools_0.5.8.1 sass_0.4.9 ## [31] bayesplot_1.11.1 yaml_2.3.8 crayon_1.5.2 ## [34] pillar_1.9.0 jquerylib_0.1.4 cachem_1.1.0 ## [37] StanHeaders_2.32.9 bridgesampling_1.1-2 abind_1.4-5 ## [40] nlme_3.1-164 posterior_1.5.0 rstan_2.32.6 ## [43] tidyselect_1.2.1 digest_0.6.35 mvtnorm_1.2-5 ## [46] stringi_1.8.4 dplyr_1.1.4 bookdown_0.39 ## [49] labeling_0.4.3 splines_4.4.0 fastmap_1.2.0 ## [52] grid_4.4.0 colorspace_2.1-0 cli_3.6.2 ## [55] magrittr_2.0.3 loo_2.7.0 pkgbuild_1.4.4 ## [58] utf8_1.2.4 withr_3.0.0 scales_1.3.0 ## [61] backports_1.5.0 estimability_1.5.1 rmarkdown_2.27 ## [64] matrixStats_1.3.0 emmeans_1.10.4 gridExtra_2.3 ## [67] chk_0.9.1 zoo_1.8-12 coda_0.19-4.1 ## [70] evaluate_0.23 knitr_1.47 mgcv_1.9-1 ## [73] rstantools_2.4.0 rlang_1.1.3 Rcpp_1.0.12 ## [76] xtable_1.8-4 glue_1.7.0 rstudioapi_0.16.0 ## [79] jsonlite_1.8.8 R6_2.5.1 References Greifer, Noah. 2024. cobalt: Covariate Balance Tables and Plots. https://CRAN.R-project.org/package=cobalt. Huntington-Klein, Nick, and Malcolm Barrett. 2021. causaldata: Example Data Sets for Causal Inference Textbooks. https://CRAN.R-project.org/package=causaldata. VanderWeele, Tyler J, John W Jackson, and Shanshan Li. 2016. “Causal Inference and Longitudinal Data: A Case Study of Religion and Mental Health.” Social Psychiatry and Psychiatric Epidemiology 51: 1457–66. "],["chapter-5.html", "Chapter 5 Most of Your Data is Almost Always Missing 5.1 Simulating missingness 5.2 Poststratification 5.3 Instrumental variable analysis 5.4 Bayesian instrumental variable analysis 5.5 Session info", " Chapter 5 Most of Your Data is Almost Always Missing 5.1 Simulating missingness We first simulate informative missingness where the outcome is associated with sampling… set.seed(2025) n &lt;- 1e3 bX &lt;- 2 X &lt;- rnorm(n, 0, 1) Y &lt;- bX*X + rnorm(n, 10, 5) prob_missing &lt;- plogis(Y - mean(Y)) miss &lt;- runif(n) &lt; prob_missing Y_miss &lt;- Y Y_miss[miss] &lt;- NA d_miss &lt;- data.frame(X = X, Y = Y, Y_miss = Y_miss) … And then fit two different models: First, a model fitted only on the non-missing observations and then a model on all the data, as if we had access to the full population. lm(Y_miss ~ X, data = d_miss) lm(Y ~ X, data = d_miss) library(ggplot2) ggplot(d_miss, aes(x = X, y = Y)) + geom_point(aes(color = is.na(Y_miss)), alpha = 0.5) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, linetype = &quot;solid&quot;, color = &quot;black&quot;, data = d_miss[!is.na(X_miss), ]) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, linetype = &quot;solid&quot;, color = &quot;grey60&quot;, data = d_miss) + scale_color_manual(values = c(&quot;black&quot;, &quot;grey&quot;), labels = c(&quot;Observed&quot;, &quot;Missing&quot;)) + labs(title = &quot;Simulating missingness&quot;, subtitle = &quot;Models with (black) and without (grey) missingness&quot;, x = &quot;X&quot;, y = &quot;Y&quot;) + theme_classic() + theme(legend.position = &quot;none&quot;) ## Error in eval(expr, envir, enclos): objekt &#39;X_miss&#39; blev ikke fundet 5.2 Poststratification To illustrate poststratification, we return to the nhefs dataset. We also load the US 2021 census, which will help us re-weight out model predictions to the greater US population. library(causaldata) d &lt;- nhefs d$sex &lt;- as.factor(d$sex) census2021 &lt;- read.csv(&quot;data/CensusUS2021.csv&quot;) We then re-score the census and the nhefs data, such that the variable levels are consistent. We also calculate census proportions from the percentages in the original census data set. census &lt;- census2021 census$age_group[census$AGE_GROUP == &quot;Under 15 years&quot;] &lt;- 1 census$age_group[census$AGE_GROUP == &quot;15 to 17 years&quot;] &lt;- 2 census$age_group[census$AGE_GROUP == &quot;18 to 20 years&quot;] &lt;- 3 census$age_group[census$AGE_GROUP == &quot;21 to 44 years&quot;] &lt;- 4 census$age_group[census$AGE_GROUP == &quot;45 to 64 years&quot;] &lt;- 5 census$age_group[census$AGE_GROUP == &quot;65 years and over&quot;] &lt;- 6 census$sex &lt;- ifelse(census$SEX == &quot;FEMALE&quot;, 1, 0) |&gt; as.factor() census$proportion &lt;- census$PERCENTAGE/100 write.csv(census, &quot;data/census_ageGroups.csv&quot;, row.names = FALSE) d2 &lt;- d d2$age_group[d2$age &lt; 15] &lt;- 1 # &quot;Under 15 years&quot; d2$age_group[d2$age &gt;= 15 &amp; d2$age &lt;= 17] &lt;- 2 # &quot;15 to 17 years&quot; d2$age_group[d2$age &gt;= 18 &amp; d2$age &lt;= 20] &lt;- 3 # &quot;18 to 20 years&quot; d2$age_group[d2$age &gt;= 21 &amp; d2$age &lt;= 44] &lt;- 4 # &quot;21 to 44 years&quot; d2$age_group[d2$age &gt;= 45 &amp; d2$age &lt;= 64] &lt;- 5 # &quot;45 to 64 years&quot; d2$age_group[d2$age &gt; 64] &lt;- 6 # &quot;65 years and over&quot; write.csv(d2, &quot;data/nhefs_ageGroups.csv&quot;, row.names = FALSE) We can then check how the two datasets compare in their distributions of the covariates age and sex. library(patchwork) library(dplyr) library(ggplot2) ### Calculate demographic proportions in the nhefs data... d3 &lt;- d2 |&gt; group_by(age_group, sex) |&gt; summarise(n = n()) |&gt; mutate(proportion = n/sum(n)) |&gt; ungroup() ### ... And fill in missing demographic combinations d3 &lt;- rbind(data.frame(age_group = c(1,1,2,2,3,3), sex = rep(c(0,1), 3), n = 0, proportion = 0), d3) ### Make age_group a factor variable d3$age_group &lt;- factor(d3$age_group, levels = 1:6) census$age_group &lt;- factor(census$age_group, levels = 1:6) ### Plotting distributions of age groups for each sex in nhefs and census ## Males p1 &lt;- ggplot() + geom_line(data = subset(d3, sex == 0), aes(x = age_group, y = proportion, group = 1), linetype = &quot;dashed&quot;, linewidth = 1) + geom_line(data = subset(census, SEX == &quot;MALE&quot;), aes(x = age_group, y = PERCENTAGE/100, group = 1), linewidth = 1) + theme_classic() + theme( axis.text.y = element_blank(), axis.ticks.y = element_blank(), axis.title.y = element_blank(), axis.line.y = element_blank(), axis.text.x = element_text(angle = -60, vjust = -1)) + scale_x_discrete(NULL, labels = c( &quot;1&quot; = &quot;Under 15 years&quot;, &quot;2&quot; = &quot;15 to 17 years&quot;, &quot;3&quot; = &quot;18 to 20 years&quot;, &quot;4&quot; = &quot;21 to 44 years&quot;, &quot;5&quot; = &quot;45 to 64 years&quot;, &quot;6&quot; = &quot;+65 years&quot;)) + labs(title = &quot;Age distributions&quot;, subtitle = &quot;Males&quot;) ## Females p2 &lt;- ggplot() + geom_line(data = subset(d3, sex == 1), aes(x = age_group, y = proportion, group = 1), linetype = &quot;dashed&quot;, linewidth = 1) + geom_line(data = subset(census, SEX == &quot;FEMALE&quot;), aes(x = age_group, y = PERCENTAGE/100, group = 1), linewidth = 1) + theme_classic() + theme( axis.text.y = element_blank(), axis.ticks.y = element_blank(), axis.title.y = element_blank(), axis.line.y = element_blank(), axis.text.x = element_text(angle = -60, vjust = -1)) + scale_x_discrete(NULL, labels = c( &quot;1&quot; = &quot;Under 15 years&quot;, &quot;2&quot; = &quot;15 to 17 years&quot;, &quot;3&quot; = &quot;18 to 20 years&quot;, &quot;4&quot; = &quot;21 to 44 years&quot;, &quot;5&quot; = &quot;45 to 64 years&quot;, &quot;6&quot; = &quot;+65 years&quot;)) + labs(subtitle = &quot;Females&quot;) (p1 + p2) 5.2.1 Frequentist poststratification We show two different poststratification implementations. First, a basic frequentist approach – see e.g. also https://github.com/RohanAlexander/mrp_workshop/blob/master/getting-started-with-mrp.Rmd First, we fit a model on the re-scored nhefs data (stored in d2) and include interactions between the exposure qsmk and each of the two covariates (sex and age&gt;_group) to make the model reasonably flexible. mod &lt;- lm(wt82_71 ~ qsmk*sex + qsmk*age_group, data = d2) We then apply g-computation with a twist. The twist is that we use the model fitted on nhefs data to get potential outcomes predictions (\\(Y^{X=1}\\) and \\(Y^{X=0}\\)) for the census data frame and then weight our predictions with the demographic proportions of each combination of sex and age group in the greater US population according to the census. We finally calculate the difference in means between the weighted predictions to get a marginal effect estimate, which we find to be around 7 kg. Before we can do any of it, however, we need to make sure that age_group is treated as numeric and sex as a factor, since this was the variable types used for model fitting. census$age_group &lt;- as.numeric(census$age_group) census$sex &lt;- as.factor(census$sex) census$EX1 &lt;- predict(mod, newdata = transform(census, qsmk = 1)) census$EX0 &lt;- predict(mod, newdata = transform(census, qsmk = 0)) census$wEX1 &lt;- census$EX1*census$proportion census$wEX0 &lt;- census$EX0*census$proportion with(census, sum(wEX1)-sum(wEX0)) ## [1] 6.991724 Here’s the code to reproduce the accompanying table in the text. xtable::xtable(census[c(&quot;AGE_GROUP&quot;, &quot;SEX&quot;, &quot;EX1&quot;, &quot;EX0&quot;,&quot;wEX1&quot;, &quot;wEX0&quot;)], digits = c(0,0,0,1,1,1,1), include.rownames=FALSE) ## % latex table generated in R 4.4.0 by xtable 1.8-4 package ## % Sat Dec 28 21:34:53 2024 ## \\begin{table}[ht] ## \\centering ## \\begin{tabular}{rllrrrr} ## \\hline ## &amp; AGE\\_GROUP &amp; SEX &amp; EX1 &amp; EX0 &amp; wEX1 &amp; wEX0 \\\\ ## \\hline ## 1 &amp; Under 15 years &amp; MALE &amp; 19.4 &amp; 13.1 &amp; 3.7 &amp; 2.5 \\\\ ## 2 &amp; 15 to 17 years &amp; MALE &amp; 15.4 &amp; 10.0 &amp; 0.6 &amp; 0.4 \\\\ ## 3 &amp; 18 to 20 years &amp; MALE &amp; 11.5 &amp; 6.8 &amp; 0.4 &amp; 0.3 \\\\ ## 4 &amp; 21 to 44 years &amp; MALE &amp; 7.5 &amp; 3.7 &amp; 2.4 &amp; 1.2 \\\\ ## 5 &amp; 45 to 64 years &amp; MALE &amp; 3.6 &amp; 0.5 &amp; 0.9 &amp; 0.1 \\\\ ## 6 &amp; 65 years and over &amp; MALE &amp; -0.4 &amp; -2.6 &amp; -0.1 &amp; -0.4 \\\\ ## 7 &amp; Under 15 years &amp; FEMALE &amp; 18.3 &amp; 12.9 &amp; 3.2 &amp; 2.3 \\\\ ## 8 &amp; 15 to 17 years &amp; FEMALE &amp; 14.4 &amp; 9.7 &amp; 0.5 &amp; 0.4 \\\\ ## 9 &amp; 18 to 20 years &amp; FEMALE &amp; 10.4 &amp; 6.6 &amp; 0.4 &amp; 0.2 \\\\ ## 10 &amp; 21 to 44 years &amp; FEMALE &amp; 6.5 &amp; 3.4 &amp; 2.0 &amp; 1.1 \\\\ ## 11 &amp; 45 to 64 years &amp; FEMALE &amp; 2.5 &amp; 0.3 &amp; 0.6 &amp; 0.1 \\\\ ## 12 &amp; 65 years and over &amp; FEMALE &amp; -1.5 &amp; -2.9 &amp; -0.3 &amp; -0.5 \\\\ ## \\hline ## \\end{tabular} ## \\end{table} 5.2.2 Bayesian poststratification We finally show a fully Bayesian poststratification routine. To showcase the difference between a single-level (i.e., fixed effects) and a multilevel (i.e., random effects) model for poststratification, we fit a Bayesian multilevel model and contrast that with the frequentist model predictions stored in census. For fitting, we again use the brms package with default priors and a seed for reproducibility. We allow the effect of the exposure qsmk vary within both sex and age_group using common R formula syntax. library(brms) bayes_mod &lt;- brm(wt82_71 ~ 1 + (1 + qsmk | sex) + (1 + qsmk | age_group), data = d2, cores = 4, seed = 42, file = &quot;fits/bayes_poststrat&quot;) Next, we do two things with this model. First, we compute the posterior mean predictions for each covariate combination without applying poststratification. library(tidybayes) ### Predict outcome when exposure X = 1 for all psEX1 &lt;- add_epred_draws(object = bayes_mod, newdata = transform(census, qsmk=1), # Predict for covariates combinations # not observed in the training data (nhefs) allow_new_levels = TRUE) |&gt; # Posterior means for each covariate combination group_by(age_group, sex) |&gt; summarise(psEX1 = mean(.epred)) ### Predict outcome when exposure X = 0 for all psEX0 &lt;- add_epred_draws(object = bayes_mod, newdata = transform(census, qsmk=0), allow_new_levels = TRUE) |&gt; group_by(age_group, sex) |&gt; summarise(psEX0 = mean(.epred)) Then, we again compute the marginal mean predictions for each covariate combination but this time applying poststratification weights. Everything else is the same. ### Predict outcome when exposure X = 1 for all wpsEX1 &lt;- add_epred_draws(object = bayes_mod, newdata = transform(census, qsmk=1), allow_new_levels = TRUE) |&gt; # New bit: Re-weight model predictions using census proportions mutate(estimate_prop = .epred*proportion) |&gt; group_by(age_group, sex, .draw) |&gt; summarise(wpsEX1 = sum(estimate_prop)) |&gt; # Posterior means for each covariate combination group_by(age_group, sex) |&gt; summarise(wpsEX1 = mean(wpsEX1)) ### Predict outcome when exposure X = 0 for all wpsEX0 &lt;- add_epred_draws(object = bayes_mod, newdata = transform(census, qsmk=0), allow_new_levels = TRUE) |&gt; mutate(estimate_prop = .epred*proportion) |&gt; group_by(age_group, sex, .draw) |&gt; summarise(wpsEX0 = sum(estimate_prop)) |&gt; group_by(age_group, sex) |&gt; summarise(wpsEX0 = mean(wpsEX0)) We then collect the posterior mean predictions and the frequentist predictions in two data frames, without and with poststratification… ### No poststratification ps &lt;- data.frame(age_group = census$AGE_GROUP, sex = census$SEX, EX1 = census$EX1, EX0 = census$EX0, psEX1 = psEX1$psEX1, psEX0 = psEX0$psEX0, E = census$EX1 - census$EX0, psE = psEX1$psEX1 - psEX0$psEX0) ps$age_group &lt;- factor(ps$age_group, levels = c( &quot;1&quot; = &quot;Under 15 years&quot;, &quot;2&quot; = &quot;15 to 17 years&quot;, &quot;3&quot; = &quot;18 to 20 years&quot;, &quot;4&quot; = &quot;21 to 44 years&quot;, &quot;5&quot; = &quot;45 to 64 years&quot;, &quot;6&quot; = &quot;65 years and over&quot;)) ### With poststratification psw &lt;- data.frame(age_group = census$AGE_GROUP, sex = census$SEX, wEX1 = census$wEX1, wEX0 = census$wEX0, wpsEX1 = wpsEX1$wpsEX1, wpsEX0 = wpsEX0$wpsEX0) psw$age_group &lt;- factor(psw$age_group, levels = c( &quot;1&quot; = &quot;Under 15 years&quot;, &quot;2&quot; = &quot;15 to 17 years&quot;, &quot;3&quot; = &quot;18 to 20 years&quot;, &quot;4&quot; = &quot;21 to 44 years&quot;, &quot;5&quot; = &quot;45 to 64 years&quot;, &quot;6&quot; = &quot;65 years and over&quot;)) … And plot the comparisons. p1 &lt;- ggplot() + geom_line(data = subset(ps, sex == &quot;FEMALE&quot;), aes(x = age_group, y = EX1, group = 1), linetype = &quot;dashed&quot;, size = 1, colour = &quot;grey60&quot;) + geom_line(data = subset(ps, sex == &quot;FEMALE&quot;), aes(x = age_group, y = psEX1, group = 1), size = 1, colour = &quot;grey60&quot;) + geom_line(data = subset(ps, sex == &quot;FEMALE&quot;), aes(x = age_group, y = EX0, group = 1), linetype = &quot;dashed&quot;, size = 1) + geom_line(data = subset(ps, sex == &quot;FEMALE&quot;), aes(x = age_group, y = psEX0, group = 1), size = 1) + theme_classic() + ylab(&quot;Weight change (kg)&quot;) + theme( axis.text.x = element_text(angle = -60, vjust = -1)) + scale_x_discrete(NULL, labels = c( &quot;1&quot; = &quot;Under 15 years&quot;, &quot;2&quot; = &quot;15 to 17 years&quot;, &quot;3&quot; = &quot;18 to 20 years&quot;, &quot;4&quot; = &quot;21 to 44 years&quot;, &quot;5&quot; = &quot;45 to 64 years&quot;, &quot;65 years and over&quot; = &quot;+65 years&quot;)) + labs(title = &quot;Predicted weight change&quot;, subtitle = &quot;No poststratification&quot;) p2 &lt;- ggplot() + geom_line(data = subset(psw, sex == &quot;FEMALE&quot;), aes(x = age_group, y = wEX1, group = 1), linetype = &quot;dashed&quot;, size = 1, colour = &quot;grey60&quot;) + geom_line(data = subset(psw, sex == &quot;FEMALE&quot;), aes(x = age_group, y = wpsEX1, group = 1), size = 1, colour = &quot;grey60&quot;) + geom_line(data = subset(psw, sex == &quot;FEMALE&quot;), aes(x = age_group, y = wEX0, group = 1), linetype = &quot;dashed&quot;, size = 1) + geom_line(data = subset(psw, sex == &quot;FEMALE&quot;), aes(x = age_group, y = wpsEX0, group = 1), size = 1) + theme_classic() + ylab(NULL) + theme( axis.text.x = element_text(angle = -60, vjust = -1)) + scale_x_discrete(NULL, labels = c( &quot;1&quot; = &quot;Under 15 years&quot;, &quot;2&quot; = &quot;15 to 17 years&quot;, &quot;3&quot; = &quot;18 to 20 years&quot;, &quot;4&quot; = &quot;21 to 44 years&quot;, &quot;5&quot; = &quot;45 to 64 years&quot;, &quot;65 years and over&quot; = &quot;+65 years&quot;)) + labs(subtitle = &quot;With poststratification&quot;) (p1 + p2) In the text, we showed predictions for females only, but the results are similar for males. p3 &lt;- ggplot() + geom_line(data = subset(ps, sex == &quot;MALE&quot;), aes(x = age_group, y = EX1, group = 1), linetype = &quot;dashed&quot;, size = 1, colour = &quot;grey60&quot;) + geom_line(data = subset(ps, sex == &quot;MALE&quot;), aes(x = age_group, y = psEX1, group = 1), size = 1, colour = &quot;grey60&quot;) + geom_line(data = subset(ps, sex == &quot;MALE&quot;), aes(x = age_group, y = EX0, group = 1), linetype = &quot;dashed&quot;, size = 1) + geom_line(data = subset(ps, sex == &quot;MALE&quot;), aes(x = age_group, y = psEX0, group = 1), size = 1) + theme_classic() + ylab(&quot;Weight change (kg)&quot;) + theme( axis.text.x = element_text(angle = -60, vjust = -1)) + scale_x_discrete(NULL, labels = c( &quot;1&quot; = &quot;Under 15 years&quot;, &quot;2&quot; = &quot;15 to 17 years&quot;, &quot;3&quot; = &quot;18 to 20 years&quot;, &quot;4&quot; = &quot;21 to 44 years&quot;, &quot;5&quot; = &quot;45 to 64 years&quot;, &quot;65 years and over&quot; = &quot;+65 years&quot;)) + labs(title = &quot;Predicted weight change&quot;, subtitle = &quot;No poststratification (males)&quot;) p4 &lt;- ggplot() + geom_line(data = subset(psw, sex == &quot;MALE&quot;), aes(x = age_group, y = wEX1, group = 1), linetype = &quot;dashed&quot;, size = 1, colour = &quot;grey60&quot;) + geom_line(data = subset(psw, sex == &quot;MALE&quot;), aes(x = age_group, y = wpsEX1, group = 1), size = 1, colour = &quot;grey60&quot;) + geom_line(data = subset(psw, sex == &quot;MALE&quot;), aes(x = age_group, y = wEX0, group = 1), linetype = &quot;dashed&quot;, size = 1) + geom_line(data = subset(psw, sex == &quot;MALE&quot;), aes(x = age_group, y = wpsEX0, group = 1), size = 1) + theme_classic() + ylab(NULL) + theme( axis.text.x = element_text(angle = -60, vjust = -1)) + scale_x_discrete(NULL, labels = c( &quot;1&quot; = &quot;Under 15 years&quot;, &quot;2&quot; = &quot;15 to 17 years&quot;, &quot;3&quot; = &quot;18 to 20 years&quot;, &quot;4&quot; = &quot;21 to 44 years&quot;, &quot;5&quot; = &quot;45 to 64 years&quot;, &quot;65 years and over&quot; = &quot;+65 years&quot;)) + labs(subtitle = &quot;With poststratification (males)&quot;) (p3 + p4) 5.2.2.1 Poststratified marginal causal effect The above workflow computed and plotted posterior means, but with a Bayesian model we have a full posterior distribution to work with. So let’s do that. This time, we’re interested in the poststratified estimate for the population as a whole. This means that we have to marginalize over the covariates, which we do by grouping on posterior draws instead of on the covariates. The rest should look familiar. ### Predict outcome when exposure X = 1 for all ateEX1 &lt;- add_epred_draws(object = bayes_mod, newdata = transform(census, qsmk=1), allow_new_levels = TRUE) |&gt; mutate(estimate_prop = .epred*proportion) |&gt; # New bit: Marginalize over covariate combinations by grouping on .draw group_by(.draw) |&gt; summarise(.epred = sum(estimate_prop)) ### Predict outcome when exposure X = 1 for all ateEX0 &lt;- add_epred_draws(object = bayes_mod, newdata = transform(census, qsmk=0), allow_new_levels = TRUE) |&gt; mutate(estimate_prop = .epred*proportion) |&gt; group_by(.draw) |&gt; summarise(.epred = sum(estimate_prop)) ### Compute poststratified ATE poststratified_ate &lt;- data.frame(EX1 = ateEX1$.epred, EX0 = ateEX0$.epred, draw = ateEX0$.draw) |&gt; # For each posterior draw... group_by(draw) |&gt; # ... Calculate ATE summarise(ate = mean(EX1 - EX0)) The poststratified marginal causal effect is around 4.7 kg but with a fairly wide 95% interval ranging from around 0 to 9 kg. mean_hdi(poststratified_ate$ate) ## y ymin ymax .width .point .interval ## 1 4.677918 0.1554798 8.870636 0.95 mean hdi Behold the full posterior poststratified marginal causal effect! ggplot(poststratified_ate, aes(x = ate)) + geom_density() + theme_classic() 5.3 Instrumental variable analysis 5.3.1 Preparing Cohen et al. (2015) We’ll use the data ACT_IllLvlMainWithMalProbs_FINAL_pub.dta from Cohen, Dupas, and Schaner (2015), which can be downloaded from the book’s Github page or www.openicpsr.org. The data need to be wrangled a little before use. Each row is an illness period, where most households only have a single illness period. A few households, however, do have more. The models we use here assume – as did the original study – illness periods to be independent. library(haven) # for loading .dta file library(dplyr) ### Load original data dta &lt;- read_dta(&quot;data/ACT_IllLvlMainWithMalProbs_FINAL_pub.dta&quot;) |&gt; as.data.frame() ### Filter data set, as the original study did -- re-use name from original analysis script all_ill_prob &lt;- subset(dta, first_ep==1 &amp; ex_post==0 &amp; rdt_any==0) ### Collaps all ACT subsidy types all_ill_prob$act_any &lt;- ifelse(all_ill_prob$act40==1 | all_ill_prob$act60==1 | all_ill_prob$act100==1, 1, 0) |&gt; as.integer() ### Replace sample-mean imputed values with NAs to allow Bayesian imputation, and then standardize all_ill_prob$B_head_age_bimps &lt;- with(all_ill_prob, ifelse(B_head_age_missing==1, NA, B_head_age_imputed)) ### Prepare data for IV and multilevel analysis cohen2015 &lt;- all_ill_prob |&gt; select(householdid, took_act, act_any, B_head_age_bimps, head_lit, used_act_v, totstrata) ### Change col names colnames(cohen2015) &lt;- c(&quot;hid&quot;, &quot;act&quot;, &quot;subsidy&quot;, &quot;age&quot;, &quot;literate&quot;, &quot;voucher&quot;, &quot;stratum&quot;) ### Declare variable types cohen2015$hid &lt;- as.factor(cohen2015$hid) cohen2015$act &lt;- as.integer(cohen2015$act) cohen2015$subsidy &lt;- as.integer(cohen2015$subsidy) cohen2015$age &lt;- as.numeric(cohen2015$age) cohen2015$literate &lt;- as.integer(cohen2015$literate) cohen2015$voucher &lt;- as.integer(cohen2015$voucher) cohen2015$stratum &lt;- as.factor(cohen2015$stratum) ### Subset data for missing data analysis cohen2015miss &lt;- cohen2015 |&gt; select(act, subsidy, age, literate) ### Export write.csv(cohen2015, &quot;data/cohen2015.csv&quot;, row.names = FALSE) write.csv(cohen2015miss, &quot;data/cohen2015miss.csv&quot;, row.names = FALSE) 5.3.2 Randomized treatment assignment as instrument d &lt;- read.csv(&quot;data/cohen2015.csv&quot;) ### Fit outcome and treatment models y_mod &lt;- glm(act ~ subsidy, data = d, family = &quot;binomial&quot;) x_mod &lt;- glm(voucher ~ subsidy, data = d, family = &quot;binomial&quot;) ### Intention-to-treat analysis YV1 &lt;- predict(y_mod, newdata = transform(d, subsidy = 1), type = &quot;response&quot;) YV0 &lt;- predict(y_mod, newdata = transform(d, subsidy = 0), type = &quot;response&quot;) itt &lt;- mean(YV1) - mean(YV0) ### &quot;Compliance analysis&quot; XV1 &lt;- predict(x_mod, newdata = transform(d, subsidy = 1), type = &quot;response&quot;) XV0 &lt;- predict(x_mod, newdata = transform(d, subsidy = 0), type = &quot;response&quot;) compliance &lt;- mean(XV1) - mean(XV0) ### Wald IV ratio estimator / Treatment-on-the-treated estimate (iv &lt;- itt/compliance) ## [1] 0.9551056 5.4 Bayesian instrumental variable analysis As mentioned in the text, we also want to demonstrate another approach to instrumental variable analysis, namely a Bayesian implementation. Kurz (2023, ch. 14) gives a rundown of instrumental variable analysis using the brms package, building on McElreath (2020), and we follow that general approach here. We refer to those sources for further details. We first define two model formulas, one for the instrument (subsidy) predicting treatment (voucher) \\(\\textrm{E}[X \\mid V]\\) and another for the treatment predicting ACT uptake (act) model \\(\\textrm{E}[Y \\mid X]\\). This is superficially similar to how we fitted y_mod and x_mod in the frequentist setting in the text and above but note a few differences: First, while the model predicting voucher use from subsidy assignment corresponds to the “compliance analysis” (x_mod), the model predicting ACT uptake from voucher use is not used for the Wald estimator. Second, in the Bayesian setup we fit the two models in the same go. In brms this is facilitated by wrapping the model formulas in bf() and then combining these in the model fitting call using +. Finally, we allow the model to estimate the residual correlation between these two models by setting set_rescor(TRUE). Why does this work as an alternative IV estimator? Recall that we use an instrumental variable approach to deal with situations where the treatment variable (here, subsidy) is correlated with the error term of the outcome model – in essence, there’s an open backdoor path between treatment and the outcome. This residual correlation could be due to unobserved confounding variables of some sort, which in turn will lead to biased estimates in a simple regression model. We account for the possibility that such confounding exists by explicitly modeling this correlation. library(brms) # Treatment-instrument model formula xv_formula &lt;- bf(voucher ~ subsidy) # Outcome-treatment model formula yx_formula &lt;- bf(act ~ voucher) # Fit models and set residual correlation = TRUE bayes_iv_mod &lt;- brm(xv_formula + yx_formula + set_rescor(TRUE), data = d, cores = 4, seed = 42, file = &quot;fits/bayes_iv&quot;) By inspecting the summary, we see that we get essentially the same results as above – act_voucher corresponds to the Wald esimate – except we now have a posterior distribution to work with. summary(bayes_iv_mod) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: voucher ~ subsidy ## act ~ voucher ## Data: d (Number of observations: 631) ## Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup draws = 4000 ## ## Regression Coefficients: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## voucher_Intercept 0.13 0.03 0.06 0.20 1.00 2810 2312 ## act_Intercept 0.07 0.06 -0.05 0.18 1.00 1313 1228 ## voucher_subsidy 0.20 0.04 0.13 0.28 1.00 2455 2216 ## act_voucher 0.96 0.20 0.60 1.40 1.00 1294 1226 ## ## Further Distributional Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_voucher 0.44 0.01 0.42 0.46 1.00 3324 2357 ## sigma_act 0.44 0.04 0.39 0.54 1.00 1366 1265 ## ## Residual Correlations: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## rescor(voucher,act) -0.38 0.17 -0.68 -0.02 1.00 1312 1184 ## ## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Now, since we don’t include covariates in these models, it’s safe to just work with the coefficients here; the marginal and conditional estimates are the same in this particular case. However, in cases where the conditional and marginal effects differ, what we’ve done here is to calculate a conditional estimate, since we’re simply working with the coefficients. To get a marginal estimate in such a case, we’d have to implement something like g-computation. An explicitly marginal workflow could look like the following, following a familiar g-computation approach: # Calculate predicted values for voucher = 1 and voucher = 0 bayes_YX1 &lt;- add_epred_draws(object = bayes_iv_mod, newdata = transform(d, voucher = 1), resp = &quot;act&quot;) bayes_YX0 &lt;- add_epred_draws(object = bayes_iv_mod, newdata = transform(d, voucher = 0), resp = &quot;act&quot;) # Bayesian marginal IV bayes_marginal_iv &lt;- data.frame(EX1 = bayes_YX1$.epred, EX0 = bayes_YX0$.epred, draw = bayes_YX0$.draw) |&gt; # For each posterior draw... group_by(draw) |&gt; # ... Calculate ATE summarise(late = mean(EX1 - EX0)) Again, in this simple example, the conditional and marginal IV results are identical. mean_qi(bayes_marginal_iv$late) ## y ymin ymax .width .point .interval ## 1 0.9575332 0.6015686 1.397755 0.95 mean qi 5.5 Session info sessionInfo() ## R version 4.4.0 (2024-04-24 ucrt) ## Platform: x86_64-w64-mingw32/x64 ## Running under: Windows 10 x64 (build 19045) ## ## Matrix products: default ## ## ## locale: ## [1] LC_COLLATE=Danish_Denmark.utf8 LC_CTYPE=Danish_Denmark.utf8 ## [3] LC_MONETARY=Danish_Denmark.utf8 LC_NUMERIC=C ## [5] LC_TIME=Danish_Denmark.utf8 ## ## time zone: Europe/Copenhagen ## tzcode source: internal ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] dplyr_1.1.4 cobalt_4.5.5 causaldata_0.1.3 sandwich_3.1-0 ## [5] patchwork_1.2.0 ggplot2_3.5.1 ## ## loaded via a namespace (and not attached): ## [1] gtable_0.3.5 tensorA_0.36.2.1 xfun_0.44 ## [4] bslib_0.7.0 QuickJSR_1.1.3 inline_0.3.19 ## [7] lattice_0.22-6 vctrs_0.6.5 tools_4.4.0 ## [10] generics_0.1.3 stats4_4.4.0 parallel_4.4.0 ## [13] tibble_3.2.1 fansi_1.0.6 highr_0.11 ## [16] pkgconfig_2.0.3 brms_2.21.0 Matrix_1.7-0 ## [19] checkmate_2.3.1 distributional_0.4.0 RcppParallel_5.1.7 ## [22] lifecycle_1.0.4 compiler_4.4.0 farver_2.1.2 ## [25] stringr_1.5.1 Brobdingnag_1.2-9 munsell_0.5.1 ## [28] codetools_0.2-20 htmltools_0.5.8.1 sass_0.4.9 ## [31] bayesplot_1.11.1 yaml_2.3.8 crayon_1.5.2 ## [34] pillar_1.9.0 jquerylib_0.1.4 cachem_1.1.0 ## [37] StanHeaders_2.32.9 bridgesampling_1.1-2 abind_1.4-5 ## [40] nlme_3.1-164 posterior_1.5.0 rstan_2.32.6 ## [43] tidyselect_1.2.1 digest_0.6.35 mvtnorm_1.2-5 ## [46] stringi_1.8.4 reshape2_1.4.4 bookdown_0.39 ## [49] labeling_0.4.3 splines_4.4.0 fastmap_1.2.0 ## [52] grid_4.4.0 colorspace_2.1-0 cli_3.6.2 ## [55] magrittr_2.0.3 loo_2.7.0 pkgbuild_1.4.4 ## [58] utf8_1.2.4 withr_3.0.0 scales_1.3.0 ## [61] backports_1.5.0 estimability_1.5.1 rmarkdown_2.27 ## [64] matrixStats_1.3.0 emmeans_1.10.4 gridExtra_2.3 ## [67] chk_0.9.1 zoo_1.8-12 coda_0.19-4.1 ## [70] evaluate_0.23 knitr_1.47 mgcv_1.9-1 ## [73] rstantools_2.4.0 rlang_1.1.3 Rcpp_1.0.12 ## [76] xtable_1.8-4 glue_1.7.0 rstudioapi_0.16.0 ## [79] jsonlite_1.8.8 plyr_1.8.9 R6_2.5.1 References Cohen, Jessica, Pascaline Dupas, and Simone Schaner. 2015. “Price Subsidies, Diagnostic Tests, and Targeting of Malaria Treatment: Evidence from a Randomized Controlled Trial.” American Economic Review 105 (2): 609–45. Kurz, A. Solomon. 2023. Statistical Rethinking with Brms, Ggplot2, and the Tidyverse: Second Edition. Version 0.4.0. https://bookdown.org/content/4857/. McElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. Second. CRC Press. "],["chapter-6.html", "Chapter 6 More Missing Data 6.1 Simple mean imputation vs. multiple imputation 6.2 “Combine then predict” or “predict then combine”? 6.3 Bayesian imputation 6.4 Session info", " Chapter 6 More Missing Data 6.1 Simple mean imputation vs. multiple imputation Here we illustrate simple mean imputation. d &lt;- read.csv(&quot;data/cohen2015miss.csv&quot;) d$age &lt;- scale(d$age) |&gt; as.numeric() d_mimp &lt;- d d_mimp$age &lt;- with(d_mimp, ifelse(is.na(age), mean(age, na.rm = T), age)) lm(act ~ subsidy + age, data = d_mimp) |&gt; summary() ## ## Call: ## lm(formula = act ~ subsidy + age, data = d_mimp) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.4774 -0.3866 -0.2396 0.5566 0.9431 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.19126 0.03555 5.380 1.05e-07 *** ## subsidy 0.19535 0.04151 4.706 3.11e-06 *** ## age -0.06592 0.01892 -3.485 0.000527 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4608 on 628 degrees of freedom ## (34 observations deleted due to missingness) ## Multiple R-squared: 0.05275, Adjusted R-squared: 0.04973 ## F-statistic: 17.49 on 2 and 628 DF, p-value: 4.074e-08 We can compare with a complete-case analysis… lm(act ~ subsidy + age, data = d) |&gt; summary() ## ## Call: ## lm(formula = act ~ subsidy + age, data = d) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.4908 -0.3978 -0.2439 0.5472 0.9378 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.19579 0.03679 5.321 1.46e-07 *** ## subsidy 0.20467 0.04291 4.769 2.33e-06 *** ## age -0.06558 0.01905 -3.443 0.000615 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.464 on 598 degrees of freedom ## (64 observations deleted due to missingness) ## Multiple R-squared: 0.05574, Adjusted R-squared: 0.05258 ## F-statistic: 17.65 on 2 and 598 DF, p-value: 3.565e-08 … As well as multiple imputation. library(mice) set.seed(1) imp &lt;- mice(d) fit &lt;- with(imp, lm(act ~ subsidy + age)) pool(fit) |&gt; summary() ## term estimate std.error statistic df p.value ## 1 (Intercept) 0.18965550 0.03496624 5.423960 550.9040 8.739647e-08 ## 2 subsidy 0.19910361 0.04072650 4.888798 580.3649 1.314949e-06 ## 3 age -0.06753163 0.01892160 -3.569022 153.9652 4.781627e-04 In all cases, the point estimate for both the intercept and effect of subsidy is around 0.20. 6.2 “Combine then predict” or “predict then combine”? In the main text we say that we have a choice to make when working with a model fitted on multiply imputed data: Do we apply Rubin’s pooling rules on the model coefficients or on model predictions? We can refer to these different approaches as “combine then predict” and “predict then combine,” respectively, following Miles (2016). Since different R packages implement post-processing of multiply imputed model fits differently, we show a basic implementations here with two popular R packages. What the packages have in common is that they allow us to conveniently work with the mice object as we would any other model fit. Let’s proceed with the malaria subsidy data and imagine we want an average treatment effect of the subsidy treatment of ACT uptake marginal of age using g-computation. 6.2.1 marginaleffects The marginaleffects package (Arel-Bundock, Greifer, and Heiss Forthcoming) implements “predict then combine”; that is, it obtains model predictions for each of the m data sets and then apply Rubin’s rules to the predictions to pool them. G-computation is very straightforward to implement. library(marginaleffects) avg_comparisons(fit, variables = list(subsidy = 0:1)) ## ## Term Contrast Estimate Std. Error t Pr(&gt;|t|) S 2.5 % 97.5 % ## subsidy mean(1) - mean(0) 0.199 0.0407 4.89 &lt;0.001 19.9 0.119 0.279 ## Df ## 5965 ## ## Columns: term, contrast, estimate, std.error, s.value, predicted_lo, predicted_hi, predicted, df, statistic, p.value, conf.low, conf.high ## Type: response 6.2.2 emmeans On the other hand, the emmeans package (R. V. Lenth 2024) implements “combine then predict”; that is, it applies Rubin’s rules to the model coefficients to pool them and only then obtain model predictions. A basic g-computation implementation could like this using emmeans. library(emmeans) emmeans(specs = &quot;subsidy&quot;, ref_grid(fit)) |&gt; contrast(&quot;revpairwise&quot;) |&gt; confint() ## contrast estimate SE df lower.CL upper.CL ## subsidy1 - subsidy0 0.199 0.0407 580 0.119 0.279 ## ## Confidence level used: 0.95 We see that results are identical to those obtained with marginaleffects. 6.2.3 Comparison But let’s try to see when the two different approaches give different results. Instead of a linear model on the imputed datasets, we instead use a non-linear model in the form of a logistic regression. We do this by calling glm() instead of lm() and setting family = \"binomial\". fit_binom &lt;- with(imp, glm(act ~ subsidy + age, family = &quot;binomial&quot;)) Then, we apply our two approaches. The marginaleffects implementation is identical to above even though the model fit is now a logistic regression. avg_comparisons(fit_binom, variables = list(subsidy = 0:1)) ## ## Term Contrast Estimate Std. Error t Pr(&gt;|t|) S 2.5 % 97.5 % ## subsidy mean(1) - mean(0) 0.201 0.0369 5.44 &lt;0.001 24.1 0.128 0.273 ## Df ## 3541 ## ## Columns: term, contrast, estimate, std.error, s.value, predicted_lo, predicted_hi, predicted, df, statistic, p.value, conf.low, conf.high ## Type: response For the emmeans approach, to get predictions on the probability scale, we can wrap the ref_grid() function in regrid() and set type = \"response\". We see that results are very similar but not identical. emmeans(specs = &quot;subsidy&quot;, regrid(ref_grid(fit_binom), type = &quot;response&quot;)) |&gt; contrast(&quot;revpairwise&quot;) |&gt; confint() ## contrast estimate SE df lower.CL upper.CL ## subsidy1 - subsidy0 0.203 0.037 1566 0.13 0.275 ## ## Confidence level used: 0.95 6.3 Bayesian imputation In the book, we also mentioned an alternative imputation approach, namely Bayesian imputation. Using the brms package (Bürkner 2017, 2018, 2021), we’ll show a very basic implementation. The syntax should seem somewhat familiar, as brms uses common R regression syntax. First, we define the model formula. At its core, it’s similar to the lm() formula above, except for a few complications. The formula object holds two main components, each wrapped by bf(). In the first part, we indicate the covariate we want to impute – in the case, age – with the mi() wrapper. The second part specifies a model for the variable we want to impute. Finally, we feed that formula to brm() along with the data. We then set the cores to 4 for speedier sampling and a seed for numeric reproducibility. We strongly recommend McElreath (and Kurz’ translations) [REF] for more details and a general introduction ot Bayesian inference more generally. library(brms) # Define model formula formula &lt;- bf(act ~ subsidy + mi(age)) + bf(age | mi() ~ 1) # Fit model to data bfit &lt;- brm(formula, data = d, cores = 4, seed = 2020, file = &quot;fits/bfit.rds&quot;) We can get a summary of the Bayesian model by calling summary() summary(bfit) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: act ~ subsidy + mi(age) ## age | mi() ~ 1 ## Data: d (Number of observations: 631) ## Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup draws = 4000 ## ## Regression Coefficients: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## act_Intercept 0.19 0.04 0.12 0.26 1.00 8466 2986 ## age_Intercept -0.02 0.04 -0.10 0.06 1.00 6946 3032 ## act_subsidy 0.20 0.04 0.12 0.28 1.00 7634 2840 ## act_miage -0.06 0.02 -0.10 -0.03 1.00 9493 2986 ## ## Further Distributional Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_act 0.46 0.01 0.44 0.49 1.00 8351 3073 ## sigma_age 1.00 0.03 0.94 1.06 1.00 6670 2543 ## ## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). The coefficient act_subsidy corresponds to the subsidy coefficient in the lm() and glm() calls above. We see that the coefficients are very similar to the models above, except now we also have coefficients for the model predicting age (the age_ parameters). Now, there are many ways to extend this model, which are outside the scope of this companion website, for instance using more informative prior settings, constraining imputed values to be within realistic ranges, include covariates in the sub-model predicting missing age values, or use a different likelihood for act that respects its binary nature (e.g., a logistic regression model). We can also inspect the distribution of imputed values. For instance, we can plot 20 draws from the distribution of the imputed age variable (light blue curves) against the observed distribution of age in the sample (dark blue curve)… pp_check(bfit, resp = &quot;age&quot;, ndraws = 20) … Which is somewhat similar to this plot of imputed data sets (red curves) against the observed (blue curve) from the mice implementation shown in the text. densityplot(imp, ~ age) Now, we can post-process the Bayesian model fit exactly as shown in Chapters 3 and 5 [REF] using the tidybayes-based workflow (Kay 2023). Or, we can use marginaleffects just as shown for the mice object above, except we need to specify that it’s the model predicting ACT uptake that we want to apply g-computation to; this is what resp = \"act\" does. avg_comparisons(bfit, variables = list(subsidy = 0:1), resp = &quot;act&quot;) ## ## Term Contrast Estimate 2.5 % 97.5 % ## subsidy mean(1) - mean(0) 0.195 0.116 0.276 ## ## Columns: term, contrast, estimate, conf.low, conf.high, predicted_lo, predicted_hi, predicted, tmp_idx ## Type: response 6.4 Session info sessionInfo() ## R version 4.4.0 (2024-04-24 ucrt) ## Platform: x86_64-w64-mingw32/x64 ## Running under: Windows 10 x64 (build 19045) ## ## Matrix products: default ## ## ## locale: ## [1] LC_COLLATE=Danish_Denmark.utf8 LC_CTYPE=Danish_Denmark.utf8 ## [3] LC_MONETARY=Danish_Denmark.utf8 LC_NUMERIC=C ## [5] LC_TIME=Danish_Denmark.utf8 ## ## time zone: Europe/Copenhagen ## tzcode source: internal ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] brms_2.21.0 Rcpp_1.0.12 emmeans_1.10.4 ## [4] marginaleffects_0.21.0 mice_3.16.0 dplyr_1.1.4 ## [7] cobalt_4.5.5 causaldata_0.1.3 sandwich_3.1-0 ## [10] patchwork_1.2.0 ggplot2_3.5.1 ## ## loaded via a namespace (and not attached): ## [1] tidyselect_1.2.1 farver_2.1.2 loo_2.7.0 ## [4] fastmap_1.2.0 tensorA_0.36.2.1 rpart_4.1.23 ## [7] digest_0.6.35 estimability_1.5.1 lifecycle_1.0.4 ## [10] StanHeaders_2.32.9 survival_3.5-8 magrittr_2.0.3 ## [13] posterior_1.5.0 compiler_4.4.0 rlang_1.1.3 ## [16] sass_0.4.9 tools_4.4.0 utf8_1.2.4 ## [19] yaml_2.3.8 collapse_2.0.14 data.table_1.15.4 ## [22] knitr_1.47 labeling_0.4.3 bridgesampling_1.1-2 ## [25] pkgbuild_1.4.4 plyr_1.8.9 abind_1.4-5 ## [28] withr_3.0.0 purrr_1.0.2 nnet_7.3-19 ## [31] grid_4.4.0 stats4_4.4.0 fansi_1.0.6 ## [34] jomo_2.7-6 xtable_1.8-4 colorspace_2.1-0 ## [37] inline_0.3.19 MASS_7.3-60.2 scales_1.3.0 ## [40] iterators_1.0.14 insight_0.20.1 cli_3.6.2 ## [43] mvtnorm_1.2-5 rmarkdown_2.27 crayon_1.5.2 ## [46] generics_0.1.3 RcppParallel_5.1.7 rstudioapi_0.16.0 ## [49] reshape2_1.4.4 minqa_1.2.7 cachem_1.1.0 ## [52] rstan_2.32.6 stringr_1.5.1 splines_4.4.0 ## [55] bayesplot_1.11.1 parallel_4.4.0 matrixStats_1.3.0 ## [58] vctrs_0.6.5 boot_1.3-30 glmnet_4.1-8 ## [61] Matrix_1.7-0 jsonlite_1.8.8 bookdown_0.39 ## [64] mitml_0.4-5 foreach_1.5.2 jquerylib_0.1.4 ## [67] tidyr_1.3.1 glue_1.7.0 pan_1.9 ## [70] nloptr_2.0.3 chk_0.9.1 codetools_0.2-20 ## [73] distributional_0.4.0 stringi_1.8.4 gtable_0.3.5 ## [76] shape_1.4.6.1 QuickJSR_1.1.3 lme4_1.1-35.3 ## [79] munsell_0.5.1 tibble_3.2.1 pillar_1.9.0 ## [82] htmltools_0.5.8.1 Brobdingnag_1.2-9 R6_2.5.1 ## [85] evaluate_0.23 lattice_0.22-6 highr_0.11 ## [88] backports_1.5.0 broom_1.0.6 bslib_0.7.0 ## [91] rstantools_2.4.0 coda_0.19-4.1 gridExtra_2.3 ## [94] nlme_3.1-164 checkmate_2.3.1 mgcv_1.9-1 ## [97] xfun_0.44 zoo_1.8-12 pkgconfig_2.0.3 References Arel-Bundock, Vincent, Noah Greifer, and Andrew Heiss. Forthcoming. “How to Interpret Statistical Models Using marginaleffects in R and Python.” Journal of Statistical Software, Forthcoming. Bürkner, Paul-Christian. 2017. “brms: An R Package for Bayesian Multilevel Models Using Stan.” Journal of Statistical Software 80 (1): 1–28. https://doi.org/10.18637/jss.v080.i01. ———. 2018. “Advanced Bayesian Multilevel Modeling with the R Package brms.” The R Journal 10 (1): 395–411. https://doi.org/10.32614/RJ-2018-017. ———. 2021. “Bayesian Item Response Modeling in R with brms and Stan.” Journal of Statistical Software 100 (5): 1–54. https://doi.org/10.18637/jss.v100.i05. Kay, Matthew. 2023. tidybayes: Tidy Data and Geoms for Bayesian Models. https://doi.org/10.5281/zenodo.1308151. Lenth, Russell V. 2024. emmeans: Estimated Marginal Means, Aka Least-Squares Means. https://CRAN.R-project.org/package=emmeans. Miles, Andrew. 2016. “Obtaining Predictions from Models Fit to Multiply Imputed Data.” Sociological Methods &amp; Research 45 (1): 175–85. https://doi.org/10.1177/0049124115610345. "],["chapter-7.html", "Chapter 7 Multilevel Modelling and Mundlak’s Legacy 7.1 Multilevel malaria medicine 7.2 Simulating Mundlak 7.3 Education and prosociality: Mundlak in action 7.4 Marginal effects in a multilevel model 7.5 Session info", " Chapter 7 Multilevel Modelling and Mundlak’s Legacy library(brms) library(ggplot2) library(patchwork) library(dplyr) library(tidybayes) 7.1 Multilevel malaria medicine To reproduce the figure comparing random and fixed effects, we first load the malaria subsidy data and fit the five models. We again use the brms package with default prior settings, but models could just as well be implemented using e.g., lme4. d &lt;- read.csv(&quot;data/cohen2015.csv&quot;) d$stratum &lt;- as.factor(d$stratum) 7.1.1 Naïve model: Simple intercept and slope msimp &lt;- brm(act ~ 1 + subsidy, data = d, cores = 4, seed = 1, file = &quot;fits/msimp&quot;) 7.1.2 Fixed effects mfix &lt;- brm(act ~ 1 + subsidy + stratum, data = d, cores = 4, seed = 1, file = &quot;fits/mfix.rds&quot;) 7.1.3 Fixed effects interacting treatment and group mfix2 &lt;- brm(act ~ 1 + subsidy * stratum, data = d, cores = 4, seed = 1, file = &quot;fits/mfix2.rds&quot;) 7.1.4 Random intercepts mran &lt;- brm(act ~ 1 + subsidy + (1 | stratum), data = d, cores = 4, seed = 1, file = &quot;fits/mran.rds&quot;) 7.1.5 Random intercepts and slopes mran2 &lt;- brm(act ~ 1 + subsidy + (1 + subsidy | stratum), data = d, cores = 4, seed = 1, file = &quot;fits/mran2.rds&quot;) 7.1.6 Plot models in a panel First, we extract and collect model coefficients in a data frame. FEREpanel &lt;- data.frame(intercept = c(fixef(msimp)[1], fixef(mran)[1], coef(mran)$stratum[,1,1], fixef(mran2)[1], coef(mran2)$stratum[,1,1], fixef(mfix)[1], fixef(mfix)[3:29] + fixef(mfix)[1], fixef(mfix2)[1], fixef(mfix2)[3:29] + fixef(mfix2)[1]), slope = c(fixef(msimp)[1], fixef(mran)[2], coef(mran)$stratum[,1,2], fixef(mran2)[2], coef(mran2)$stratum[,1,2], rep(fixef(mfix)[2],28), fixef(mfix2)[2], fixef(mfix2)[30:56] + fixef(mfix2)[2]), g = c(1, rep(1:29, 2), rep(1:28, 2)), grand = c(1, 1, rep(0,28), 1, rep(0,28), rep(0, 56)), model = c(&quot;Y ~ 1 + X&quot;, rep(&quot;Y ~ 1 + X + (1 | G)&quot;, 29), rep(&quot;Y ~ 1 + X + (1 + X | G)&quot;, 29), rep(&quot;Y ~ 1 + X + G&quot;, 28), rep(&quot;Y ~ 1 + X * G&quot;, 28))) Next, we generate predictions from each of the models. # Define a range of x-values (here, it&#39;s simply control (X = 0) vs. treatment (X = 1) x_values &lt;- seq(0, 1, by = 1) # Expand the dataframe to include x-values for each line... FEREpanel &lt;- FEREpanel |&gt; tidyr::expand_grid(x = x_values) |&gt; # ... and compute predictions for control vs. treatment dplyr::mutate(y = intercept + slope * x) Then we plot predictions from each of the models # Set y-axis limit ylim &lt;- c(0,1) # Generate individual plots p1 &lt;- FEREpanel |&gt; filter(model == &quot;Y ~ 1 + X&quot;) |&gt; ggplot(aes(x = x, y = y)) + geom_line() + theme_classic() + labs(subtitle = &quot;Simple intercept and slope&quot;, title = &quot;Y ~ 1 + X&quot;, y = NULL, x = NULL) + scale_x_continuous(breaks = c(0,1), labels = c(&quot;Control&quot;, &quot;Treatment&quot;), expand = c(0.1, 0.1)) + coord_cartesian(ylim = ylim) p2 &lt;- FEREpanel |&gt; filter(model == &quot;Y ~ 1 + X + G&quot;) |&gt; ggplot(aes(x = x, y = y, group = g)) + geom_line(alpha = 0.15) + theme_classic() + theme(legend.position = &quot;none&quot;) + labs(subtitle = &quot;Fixed effects&quot;, title = &quot;Y ~ 1 + X + G&quot;, y = &quot;Prob. of taking ACT&quot;, x = NULL) + scale_x_continuous(breaks = c(0,1), labels = c(&quot;Control&quot;, &quot;Treatment&quot;), expand = c(0.1, 0.1)) + coord_cartesian(ylim = ylim) p3 &lt;- FEREpanel |&gt; filter(model == &quot;Y ~ 1 + X * G&quot;) |&gt; ggplot(aes(x = x, y = y, group = g)) + geom_line(alpha = 0.15) + theme_classic() + theme(legend.position = &quot;none&quot;, axis.ticks.y = element_blank(), axis.text.y = element_blank()) + labs(subtitle = &quot;FE interacting X and group&quot;, title = &quot;Y ~ 1 + X * G&quot;, y = NULL, x = NULL) + scale_x_continuous(breaks = c(0,1), labels = c(&quot;Control&quot;, &quot;Treatment&quot;), expand = c(0.1, 0.1)) + coord_cartesian(ylim = ylim) p4 &lt;- FEREpanel |&gt; filter(model == &quot;Y ~ 1 + X + (1 | G)&quot;) |&gt; ggplot(aes(x = x, y = y, group = g, alpha = factor(grand))) + geom_line() + scale_alpha_manual(values = c(0.15, 1)) + theme_classic() + theme(legend.position = &quot;none&quot;) + labs(subtitle = &quot;Random intercepts&quot;, title = &quot;Y ~ 1 + X + (1 | G)&quot;, y = NULL, x = NULL) + scale_x_continuous(breaks = c(0,1), labels = c(&quot;Control&quot;, &quot;Treatment&quot;), expand = c(0.1, 0.1)) + coord_cartesian(ylim = ylim) p5 &lt;- FEREpanel |&gt; filter(model == &quot;Y ~ 1 + X + (1 + X | G)&quot;) |&gt; ggplot(aes(x = x, y = y, group = g, alpha = factor(grand))) + geom_line() + scale_alpha_manual(values = c(0.15, 1)) + theme_classic() + theme(legend.position = &quot;none&quot;, axis.ticks.y = element_blank(), axis.text.y = element_blank()) + labs(subtitle = &quot;Random intercepts and slopes&quot;, title = &quot;Y ~ 1 + X + (1 + X | G)&quot;, y = NULL, x = NULL) + scale_x_continuous(breaks = c(0,1), labels = c(&quot;Control&quot;, &quot;Treatment&quot;), expand = c(0.1, 0.1)) + coord_cartesian(ylim = ylim) Finally, we panel the individual plots using the patchwork package layout &lt;- &quot; A# BC DE &quot; (p1 + p2 + p3 + p4 + p5 + plot_layout(design = layout)) 7.1.7 Regularized vs. empirical estimates In the text, we show an alternative way to demonstrate partial pooling in a multilevel model. This is where we compare the regularized predictions from a multilevel model against the “empirical” estimates from a fixed effects model. We re-use the model objects from above, mfix2 and mran2, where the treatment effect is allowed to vary by strata. First, we create two data frames that include the estimated treatment effect for each randomization stratum for each of the two models. # Fixed effects treatment effects coeffix &lt;- data.frame( strata = 1:28, coef = fixef(mfix2)[c(2, 30:56), 1]) coeffix$coef[2:28] &lt;- coeffix$coef[2:28] + coeffix$coef[1] # Random effects treatment effects coefran &lt;- data.frame( strata = 1:28, coef = coef(mran2)$stratum[,&quot;Estimate&quot;, &quot;subsidy&quot;]) # Compute strata sample sizes N &lt;- d |&gt; group_by(stratum) |&gt; summarise(N = n()) # Input strata sample sizes in data frames coeffix$N &lt;- N$N coefran$N &lt;- N$N # Arrange data frames according to strata sample sizes coeffix &lt;- coeffix |&gt; arrange(N) coeffix$strata &lt;- factor(coeffix$strata, levels = coeffix$strata) coefran &lt;- coefran |&gt; arrange(N) coefran$strata &lt;- factor(coefran$strata, levels = coefran$strata) Then, we plot the stratum-specific treatment effects. ggplot() + geom_rect(aes(xmin = -Inf, xmax = Inf, ymin = 0.07, ymax = 0.3), fill = &quot;lightgrey&quot;, alpha = 0.35) + geom_hline(yintercept = 0.19, linetype = &quot;dashed&quot;, alpha = 0.2, linewidth = 0.7) + geom_line(data = rbind(coeffix, coefran), aes(x = strata, y = coef, group = strata), linewidth = 0.25, alpha = 0.5) + geom_point(data = coeffix, aes(x = strata, y = coef), size = 1.5, alpha = 0.9, shape = 1) + geom_point(data = coefran, aes(x = strata, y = coef), size = 1.5, color = &quot;black&quot;) + ylab(&quot;Treatment Effect&quot;) + xlab(&quot;Randomization Strata\\n(smallest to largest)&quot;) + theme_classic() + theme(axis.text.x = element_blank(), axis.ticks = element_blank()) Instead of using a fixed effects model, an alternative way to compute the “empirical” estimates would be to, within each stratum, take the mean of the outcome variable act for the control (subsidy = 0) and treatment (subsidy = 1) groups separately and then subtract those values. d |&gt; # within each stratum and for each subsidy condition (control vs. treatment)... group_by(stratum, subsidy) |&gt; # ... take the mean of the outcome variable summarise(&quot;T&quot; = mean(act, na.rm = T)) |&gt; # wrangle and name columns tidyr::pivot_wider(names_from = &quot;subsidy&quot;, values_from = &quot;T&quot;, names_prefix = &quot;T&quot;) |&gt; ungroup() |&gt; mutate(coef = T1 - T0) 7.2 Simulating Mundlak Here we show the simulation and plotting code for the synthetic Mundlak demonstration. First, we simulate the confounded data and store it in d_sim set.seed(2025) # define sample size and effects N_groups &lt;- 30 N_id &lt;- 500 a &lt;- 0 bZY &lt;- 1 bXY &lt;- 0.5 g &lt;- sample(1:N_groups, size = N_id, replace = TRUE) # sample into groups Ug &lt;- rnorm(N_groups, 1.5, 1) # group confounds X &lt;- rnorm(N_id, Ug[g], 1) # individual varying trait Z &lt;- rnorm(N_groups, 0, 1) # group varying trait (observed) Y &lt;- rnorm(N_id, a + bXY*X + Ug[g] + bZY*Z[g] ) # collect in data frame d_sim &lt;- data.frame( Y = Y, X = X, Z = Z[g], G = as.factor(g) ) To properly quantify uncertainty and obtain neat posterior distributions of the effects from each model, we again analyze the data in a Bayesian framework using brms with default priors. We fit our four models. 7.2.1 Naïve model (ignoring group) mNA &lt;- brm(Y ~ X + Z, cores = 4, data = d_sim, seed = 1, file = &quot;fits/mNA.rds&quot;) 7.2.2 Fixed effects mFE &lt;- brm(Y ~ X + G, cores = 4, data = d_sim, seed = 1, file = &quot;fits/mFE.rds&quot;) 7.2.3 Random intercepts mRE &lt;- brm(Y ~ X + Z + (1 | G), cores = 4, data = d_sim, seed = 1, file = &quot;fits/mRE.rds&quot;) 7.2.4 Mundlak model d_sim$Xbar &lt;- with(d_sim, ave(X, G, FUN = mean)) mMU &lt;- brm(Y ~ X + Xbar + Z + (1 | G), cores = 4, data = d_sim, seed = 1, file = &quot;fits/mMU.rds&quot;) 7.2.5 Plot effect estimate distributions First, we extract posterior distributions of the coefficient of interest (X) from each model and collect in a data frame. ndraws &lt;- nrow(brms::as_draws_df(mNA, variable = &quot;b_X&quot;)) forest &lt;- data.frame(bX = c(brms::as_draws_df(mNA, variable = &quot;b_X&quot;)$b_X, brms::as_draws_df(mFE, variable = &quot;b_X&quot;)$b_X, brms::as_draws_df(mRE, variable = &quot;b_X&quot;)$b_X, brms::as_draws_df(mMU, variable = &quot;b_X&quot;)$b_X), model = c(rep(&quot;Naïve model\\nY ~ X + Z&quot;, ndraws), rep(&quot;Fixed effects\\nY ~ X + Z + G&quot;, ndraws), rep(&quot;Random effects\\nY ~ X + Z + (1 | G)&quot;, ndraws), rep(&quot;Mundlak model\\nY ~ X + Xbar + Z + (1 | G)&quot;, ndraws))) Next, the models are arranged… forest$model &lt;- factor(forest$model, levels=c(&quot;Naïve model\\nY ~ X + Z&quot;, &quot;Fixed effects\\nY ~ X + Z + G&quot;, &quot;Random effects\\nY ~ X + Z + (1 | G)&quot;, &quot;Mundlak model\\nY ~ X + Xbar + Z + (1 | G)&quot;)) |&gt; forcats::fct_rev() … and then plotted. forest |&gt; ggplot(aes(y = model, x = bX)) + stat_halfeye(slab_fill = &quot;white&quot;, slab_color = &quot;grey40&quot;, color = &quot;white&quot;) + geom_vline(xintercept = 0.5, linetype = &quot;dashed&quot;, alpha = 0.5) + labs(y = NULL, x = &quot;Regression coefficient&quot;) + scale_x_continuous(breaks = c(0.25, 0.5, 0.75, 1)) + theme_classic() 7.3 Education and prosociality: Mundlak in action We finally show the Mundlak model in action in real-world data. We load the cerc data (Martin Lang et al. 2019) and plot the raw data distribution for the key predictor and outcome variable, respectively, before fitting and plotting our four models. cerc &lt;- read.csv(&quot;data/cerc.csv&quot;) 7.3.1 Raw data distributions cerc |&gt; ggplot(aes(x = FORMALED)) + geom_density(aes(y = after_stat(scaled))) + facet_wrap(~ SITE, nrow = 2) + labs(y = NULL, x = NULL) + scale_x_continuous(n.breaks = 3) + scale_y_continuous(breaks = NULL) + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) + theme_classic() + ggtitle(&quot;Years of formal education&quot;) cerc |&gt; ggplot(aes(x = Y)) + geom_density(aes(y = after_stat(scaled))) + facet_wrap(~ SITE, nrow = 2) + labs(y = NULL, x = NULL) + scale_x_continuous(n.breaks = 3) + scale_y_continuous(breaks = NULL) + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) + theme_classic() + ggtitle(&quot;Coins to co-player&quot;) 7.3.2 Naïve model mNAcerc &lt;- brm(Y ~ 1 + FORMALED, data = cerc, cores = 4, seed = 1, file = &quot;fits/mNAcerc.rds&quot;) 7.3.3 Fixed effects mFEcerc &lt;- brm(Y ~ 1 + FORMALED+ SITE, data = cerc, cores = 4, seed = 1, file = &quot;fits/mFEcerc.rds&quot;) 7.3.4 Random effects mREcerc &lt;- brm(Y ~ 1 + FORMALED + (1 | SITE), data = cerc, cores = 4, seed = 1, file = &quot;fits/mREcerc.rds&quot;) 7.3.5 Mundlak model cerc$Xbar &lt;- with(cerc, ave(FORMALED, SITE, FUN = mean)) mMUcerc &lt;- brm(Y ~ 1 + FORMALED + Xbar + (1 | SITE), data = cerc, cores = 4, seed = 1, file = &quot;fits/mMUcerc.rds&quot;) 7.3.6 Plotting effect of education on religiosity The code for this plot is much the same as for the simulated Mundlak example above. ndraws &lt;- nrow(brms::as_draws_df(mNAcerc, variable = &quot;b_FORMALED&quot;)) forestcerc &lt;- data.frame(bX = c(brms::as_draws_df(mNAcerc, variable = &quot;b_FORMALED&quot;)$b_FORMALED, brms::as_draws_df(mFEcerc, variable = &quot;b_FORMALED&quot;)$b_FORMALED, brms::as_draws_df(mREcerc, variable = &quot;b_FORMALED&quot;)$b_FORMALED, brms::as_draws_df(mMUcerc, variable = &quot;b_FORMALED&quot;)$b_FORMALED), model = c(rep(&quot;Naïve model&quot;, ndraws), rep(&quot;Fixed effects&quot;, ndraws), rep(&quot;Random effects&quot;, ndraws), rep(&quot;Mundlak model&quot;, ndraws))) forestcerc$model &lt;- factor(forestcerc$model, levels=c(&quot;Naïve model&quot;, &quot;Fixed effects&quot;, &quot;Random effects&quot;, &quot;Mundlak model&quot;)) |&gt; forcats::fct_rev() forestcerc |&gt; ggplot(aes(y = model, x = bX)) + stat_halfeye(point_interval = &quot;mean_hdci&quot;, .width = 0.95, slab_fill = &quot;white&quot;, slab_color = &quot;grey40&quot;, color = &quot;white&quot;) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, alpha = 0.5) + labs(title = &quot;Cross-cultural Dictator Game&quot;, y = NULL, x = &quot;Effect of Education on Prosociality&quot;) + theme_classic() 7.4 Marginal effects in a multilevel model As we discuss in the text, there are several ways of obtaining predictions from a multilevel model, including predictions for each site, for an average site and marginal of site. Note that we here show a general g-computation approach, where we first compute marginal effects within each MCMC draw (group_by(.draw, ...) |&gt; summarise(.epred = mean(.epred))), before summarizing by the posterior mean and quantile intervals across MCMC draws (group_by(FORMALED) |&gt; summarise(.epred = mean_qi(.epred))). In the current data example, the group_by(.draw, ...) step is redundant, but it’s how we would go about applying g-computation to obtain marginal effects in a setting with a continuous focal (causal) predictor and with possible covariates and nonlinearities. First, we fit an extended Mundlak model, that allows the effect of education on religiosity to vary by site. mMUcerc2 &lt;- brm(Y ~ 1 + FORMALED + Xbar + (1 + FORMALED | SITE), data = cerc, cores = 4, seed = 1, file = &quot;fits/mMUcerc2.rds&quot;) 7.4.1 Predicting the observed sites We can then visualize effect estimates for each group (field site, in this case) across the full range of observed education years and at site-specific average years of education. # prepare prediction grid across full range of education years... nd &lt;- tidyr::expand_grid(FORMALED = c(0,10,20,30), SITE = unique(cerc$SITE)) # ... and at site-specific average years of education nd$Xbar &lt;- rep(unique(cerc$Xbar), length(unique(nd$FORMALED))) Plot predictions for each site in separate panels. For this, we need to include the random effects in the predictions. # Predict effect estimates... add_epred_draws(mMUcerc2, # for prediction grid and... newdata = nd, # ... *include* all random effect components. re_formula = NULL) |&gt; # Compute average effect *within* each MCMC draw. group_by(.draw, SITE, FORMALED) |&gt; summarise(.epred = mean(.epred)) |&gt; # Summarise average effect *across* each MCMC draw # for each site and educational level. group_by(SITE, FORMALED) |&gt; summarise(mean_qi(.epred)) |&gt; # Plot! ggplot(aes(x = FORMALED, y = y, ymin = ymin, ymax = ymax)) + geom_lineribbon(color = &quot;blue&quot;, fill = &quot;grey90&quot;, linewidth = 0.5) + coord_cartesian(ylim = c(0,8)) + facet_wrap(~SITE, nrow = 2) + theme_classic() + theme(legend.position = &quot;none&quot;) + labs(title = &quot;Predicting the observed sites&quot;, subtitle = &quot;Including random effects&quot;, x = &quot;Years of education&quot;, y = &quot;Coins to co-player&quot;) But we can also ignore site-specific effects altogether and instead aim at predicting a perfectly average site. This amounts to ignoring the random effects of the model. We first need to set up a new prediction grid for the new hypothetical site – let’s call it “Newland” – with an average of 7 years of education, the average of the site averages (this can be checked by running mean(unique(cerc$Xbar))). nd2 &lt;- tidyr::expand_grid(FORMALED = c(0,10,20,30), SITE = &quot;Newland&quot;, # could also just set to NA Xbar = 7) # could also make a distribution of Xbars to average over # Predict effect estimates... p1 &lt;- add_epred_draws(mMUcerc2, # for new prediction grid and... newdata = nd2, # ... *ignore* all random effect components. re_formula = NA) |&gt; # Compute average effect *within* each MCMC draw. group_by(.draw, FORMALED) |&gt; summarise(.epred = mean(.epred)) |&gt; # Summarise average effect *across* MCMC draws # for each educational level. group_by(FORMALED) |&gt; summarise(mean_qi(.epred)) |&gt; # Plot! ggplot(aes(x = FORMALED, y = y, ymin = ymin, ymax = ymax)) + geom_lineribbon(color = &quot;blue&quot;, fill = &quot;grey90&quot;, linewidth = 0.5) + coord_cartesian(ylim = c(0,8)) + scale_fill_brewer() + theme_classic() + theme(legend.position = &quot;none&quot;) + labs(title = &quot;Predicting the average site&quot;, subtitle = &quot;Ignoring random effects&quot;, x = &quot;Years of education&quot;, y = &quot;Coins to co-player&quot;) And finally, we could be interested in predicting a new site drawing from all that we know about the observed sites. This amounts to averaging over – instead of ignoring, as above – the uncertainty that we have around the observed sites and generating predictions from that. # Predict effect estimates... p2 &lt;- add_epred_draws(mMUcerc2, # for prediction grid and... newdata = nd2, # ... *include* all random effect components. re_formula = NULL, # Allow predictions for an unobserved group and... allow_new_levels = TRUE, # ... sample from the implied multivariate gaussian. sample_new_levels = &quot;gaussian&quot;) |&gt; # Compute average effect *within* each MCMC draw. group_by(.draw, FORMALED) |&gt; summarise(.epred = mean(.epred)) |&gt; # Summarise average causal effect across MCMC draws # for each educational level. group_by(FORMALED) |&gt; summarise(mean_qi(.epred)) |&gt; # Plot! ggplot(aes(x = FORMALED, y = y, ymin = ymin, ymax = ymax)) + geom_lineribbon(color = &quot;blue&quot;, fill = &quot;grey90&quot;, linewidth = 0.5) + coord_cartesian(ylim = c(0,8)) + scale_fill_brewer() + theme_classic() + theme(legend.position = &quot;none&quot;) + labs(title = &quot;Predicting a new site&quot;, subtitle = &quot;Averaging over random effects&quot;, x = &quot;Years of education&quot;, y = NULL) + scale_y_continuous(breaks = NULL) p1 + p2 + plot_layout(axis_titles = &quot;collect&quot;) 7.4.2 Frequentist workflow For completeness, we can also plot predictions for each site with a frequentist approach. First, we fit a corresponding frequentist model. library(lme4) mMUcerc2_freq &lt;- lmer(Y ~ 1 + FORMALED + Xbar + (1 + FORMALED | SITE), data = cerc) Next, we obtain predictions using the marginaleffects package to obtain confidence intervals. Now, the frequentist approach excludes uncertainty in the random effects, so it’s not entirely comparable to the predictions obtained in the text. library(marginaleffects) # Predicting the observed sites (only with uncertainty in the global/fixed effects parameters) predictions(mMUcerc2_freq, newdata = nd) |&gt; ggplot(aes(x = FORMALED, y = estimate, ymin = conf.low, ymax = conf.high)) + geom_lineribbon(color = &quot;blue&quot;, fill = &quot;grey90&quot;, linewidth = 0.5) + coord_cartesian(ylim = c(0,8)) + facet_wrap(~SITE, nrow = 2) + theme_classic() + theme(legend.position = &quot;none&quot;) + labs(title = &quot;Predicting the observed sites&quot;, subtitle = &quot;Frequentist version&quot;, x = &quot;Years of education&quot;, y = &quot;Coins to co-player&quot;) 7.5 Session info sessionInfo() ## R version 4.4.0 (2024-04-24 ucrt) ## Platform: x86_64-w64-mingw32/x64 ## Running under: Windows 10 x64 (build 19045) ## ## Matrix products: default ## ## ## locale: ## [1] LC_COLLATE=Danish_Denmark.utf8 LC_CTYPE=Danish_Denmark.utf8 ## [3] LC_MONETARY=Danish_Denmark.utf8 LC_NUMERIC=C ## [5] LC_TIME=Danish_Denmark.utf8 ## ## time zone: Europe/Copenhagen ## tzcode source: internal ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] lme4_1.1-35.3 Matrix_1.7-0 tidybayes_3.0.6 ## [4] brms_2.21.0 Rcpp_1.0.12 emmeans_1.10.4 ## [7] marginaleffects_0.21.0 mice_3.16.0 dplyr_1.1.4 ## [10] cobalt_4.5.5 causaldata_0.1.3 sandwich_3.1-0 ## [13] patchwork_1.2.0 ggplot2_3.5.1 ## ## loaded via a namespace (and not attached): ## [1] gridExtra_2.3 inline_0.3.19 rlang_1.1.3 ## [4] magrittr_2.0.3 matrixStats_1.3.0 compiler_4.4.0 ## [7] mgcv_1.9-1 loo_2.7.0 vctrs_0.6.5 ## [10] reshape2_1.4.4 stringr_1.5.1 pkgconfig_2.0.3 ## [13] shape_1.4.6.1 arrayhelpers_1.1-0 crayon_1.5.2 ## [16] fastmap_1.2.0 backports_1.5.0 labeling_0.4.3 ## [19] utf8_1.2.4 rmarkdown_2.27 nloptr_2.0.3 ## [22] purrr_1.0.2 xfun_0.44 glmnet_4.1-8 ## [25] jomo_2.7-6 cachem_1.1.0 jsonlite_1.8.8 ## [28] collapse_2.0.14 highr_0.11 chk_0.9.1 ## [31] pan_1.9 broom_1.0.6 parallel_4.4.0 ## [34] R6_2.5.1 bslib_0.7.0 stringi_1.8.4 ## [37] StanHeaders_2.32.9 boot_1.3-30 rpart_4.1.23 ## [40] jquerylib_0.1.4 estimability_1.5.1 bookdown_0.39 ## [43] rstan_2.32.6 iterators_1.0.14 knitr_1.47 ## [46] zoo_1.8-12 bayesplot_1.11.1 splines_4.4.0 ## [49] nnet_7.3-19 tidyselect_1.2.1 rstudioapi_0.16.0 ## [52] abind_1.4-5 yaml_2.3.8 codetools_0.2-20 ## [55] pkgbuild_1.4.4 lattice_0.22-6 tibble_3.2.1 ## [58] plyr_1.8.9 withr_3.0.0 bridgesampling_1.1-2 ## [61] posterior_1.5.0 coda_0.19-4.1 evaluate_0.23 ## [64] survival_3.5-8 RcppParallel_5.1.7 ggdist_3.3.2 ## [67] pillar_1.9.0 tensorA_0.36.2.1 checkmate_2.3.1 ## [70] foreach_1.5.2 stats4_4.4.0 insight_0.20.1 ## [73] distributional_0.4.0 generics_0.1.3 rstantools_2.4.0 ## [76] munsell_0.5.1 scales_1.3.0 minqa_1.2.7 ## [79] xtable_1.8-4 glue_1.7.0 tools_4.4.0 ## [82] data.table_1.15.4 forcats_1.0.0 mvtnorm_1.2-5 ## [85] grid_4.4.0 tidyr_1.3.1 QuickJSR_1.1.3 ## [88] colorspace_2.1-0 nlme_3.1-164 cli_3.6.2 ## [91] svUnit_1.0.6 fansi_1.0.6 Brobdingnag_1.2-9 ## [94] gtable_0.3.5 sass_0.4.9 digest_0.6.35 ## [97] farver_2.1.2 htmltools_0.5.8.1 lifecycle_1.0.4 ## [100] mitml_0.4-5 MASS_7.3-60.2 References Lang, Martin, Benjamin G Purzycki, Coren L Apicella, Quentin D Atkinson, Alexander Bolyanatz, Emma Cohen, Carla Handley, et al. 2019. “Moralizing Gods, Impartiality and Religious Parochialism Across 15 Societies.” Proceedings of the Royal Society B 286 (1898): 20190202. "],["pkgs.html", "Chapter 8 Package Citations", " Chapter 8 Package Citations library(grateful) pkgs &lt;- cite_packages(output = &quot;table&quot;, out.dir = &quot;.&quot;, cite.tidyverse = TRUE, dependencies = TRUE) knitr::kable(pkgs) Package Version Citation abind 1.4.5 Plate and Heiberger (2016) arrayhelpers 1.1.0 Beleites (2020) backports 1.5.0 Michel Lang, Murdoch, and R Core Team (2024) base 4.4.0 R Core Team (2024) base64enc 0.1.3 Urbanek (2015) bayesplot 1.11.1 Gabry et al. (2019); Gabry and Mahr (2024) BH 1.84.0.0 Eddelbuettel, Emerson, and Kane (2024) bit 4.0.5 Oehlschlägel and Ripley (2022) bit64 4.0.5 Oehlschlägel and Silvestri (2020) bookdown 0.39 Xie (2016); Xie (2024a) bridgesampling 1.1.2 Gronau, Singmann, and Wagenmakers (2020) brms 2.21.0 Bürkner (2017); Bürkner (2018); Bürkner (2021) Brobdingnag 1.2.9 Hankin (2007) bslib 0.7.0 Sievert, Cheng, and Aden-Buie (2024) cachem 1.1.0 Chang (2024a) callr 3.7.6 Csárdi and Chang (2024a) causaldata 0.1.3 Huntington-Klein and Barrett (2021) checkmate 2.3.1 Michel Lang (2017) chk 0.9.1 Thorley, Müller, and Pearson (2023) clipr 0.8.0 Lincoln (2022) cobalt 4.5.5 Greifer (2024) coda 0.19.4.1 Plummer et al. (2006) colorspace 2.1.0 Zeileis, Hornik, and Murrell (2009); Stauffer et al. (2009); Zeileis et al. (2020) cpp11 0.4.7 Vaughan, Hester, and François (2023) crayon 1.5.2 Csárdi (2022) data.table 1.15.4 Barrett et al. (2024) desc 1.4.3 Csárdi, Müller, and Hester (2023) digest 0.6.35 Antoine Lucas et al. (2024) distributional 0.4.0 O’Hara-Wild, Kay, and Hayes (2024) emmeans 1.10.4 R. V. Lenth (2024) estimability 1.5.1 R. Lenth (2024) evaluate 0.23 H. Wickham and Xie (2023) fansi 1.0.6 Gaslam (2023) farver 2.1.2 Pedersen, Nicolae, and François (2024) fastmap 1.2.0 Chang (2024b) fontawesome 0.5.2 Iannone (2023) foreach 1.5.2 Microsoft and Weston (2022) fs 1.6.4 Hester, Wickham, and Csárdi (2024) future 1.33.2 Bengtsson (2021) future.apply 1.11.2 Bengtsson (2021) generics 0.1.3 H. Wickham, Kuhn, and Vaughan (2022) ggdist 3.3.2 Kay (2024b); Kay (2024a) ggridges 0.5.6 Wilke (2024) glmnet 4.1.8 Friedman, Tibshirani, and Hastie (2010); Simon et al. (2011); Tay, Narasimhan, and Hastie (2023) globals 0.16.3 Bengtsson (2024a) glue 1.7.0 Hester and Bryan (2024) gridExtra 2.3 Auguie (2017) gtable 0.3.5 H. Wickham and Pedersen (2024) highr 0.11 Xie and Qiu (2024) htmltools 0.5.8.1 Cheng, Sievert, et al. (2024) inline 0.3.19 Sklyar et al. (2021) insight 0.20.1 Lüdecke, Waggoner, and Makowski (2019) isoband 0.2.7 H. Wickham, Wilke, and Pedersen (2022) iterators 1.0.14 Analytics and Weston (2022) jomo 2.7.6 Quartagno and Carpenter (2023) jquerylib 0.1.4 Sievert and Cheng (2021) knitr 1.47 Xie (2014); Xie (2015); Xie (2024b) labeling 0.4.3 Justin Talbot (2023) lifecycle 1.0.4 Henry and Wickham (2023) listenv 0.9.1 Bengtsson (2024b) lme4 1.1.35.3 Bates et al. (2015) loo 2.7.0 Vehtari, Gelman, and Gabry (2017); Yao et al. (2017); Vehtari et al. (2024) marginaleffects 0.21.0 Arel-Bundock, Greifer, and Heiss (Forthcoming) matrixStats 1.3.0 Bengtsson (2024c) memoise 2.0.1 H. Wickham et al. (2021) mice 3.16.0 van Buuren and Groothuis-Oudshoorn (2011) mime 0.12 Xie (2021) minqa 1.2.7 Bates et al. (2024) mitml 0.4.5 Grund, Robitzsch, and Luedtke (2023) munsell 0.5.1 C. Wickham (2024) mvtnorm 1.2.5 Genz and Bretz (2009) nleqslv 3.3.5 Hasselman (2023) nloptr 2.0.3 S. G. Johnson (?) numDeriv 2016.8.1.1 Gilbert and Varadhan (2019) ordinal 2023.12.4 Christensen (2023) pan 1.9 Zhao and Schafer (2023) parallelly 1.37.1 Bengtsson (2024d) patchwork 1.2.0 Pedersen (2024) pkgbuild 1.4.4 H. Wickham, Hester, and Csárdi (2024) pkgconfig 2.0.3 Csárdi (2019) plyr 1.8.9 H. Wickham (2011) posterior 1.5.0 Vehtari et al. (2021); Bürkner et al. (2023) prettyunits 1.2.0 Csardi (2023) processx 3.8.4 Csárdi and Chang (2024b) progress 1.2.3 Csárdi and FitzJohn (2023) ps 1.7.6 Loden et al. (2024) quadprog 1.5.8 Berwin A. Turlach R port by Andreas Weingessel &lt;Andreas.Weingessel@ci.tuwien.ac.at&gt; Fortran contributions from Cleve Moler dpodi/LINPACK) (2019) QuickJSR 1.1.3 A. R. Johnson (2024) R6 2.5.1 Chang (2021) rappdirs 0.3.3 Ratnakumar, Mick, and Davis (2021) RColorBrewer 1.1.3 Neuwirth (2022) Rcpp 1.0.12 Eddelbuettel and François (2011); Eddelbuettel (2013); Eddelbuettel and Balamuta (2018); Eddelbuettel et al. (2024) RcppEigen 0.3.4.0.0 Bates and Eddelbuettel (2013) RcppParallel 5.1.7 Allaire et al. (2023) remotes 2.5.0 Csárdi et al. (2024) renv 1.0.11 Ushey and Wickham (2024) reshape2 1.4.4 H. Wickham (2007) rmarkdown 2.27 Xie, Allaire, and Grolemund (2018); Xie, Dervieux, and Riederer (2020); Allaire et al. (2024) rstan 2.32.6 Stan Development Team (2024) rstantools 2.4.0 Gabry et al. (2024) sandwich 3.1.0 Zeileis (2004); Zeileis (2006); Zeileis, Köll, and Graham (2020) sass 0.4.9 Cheng, Mastny, et al. (2024) scales 1.3.0 H. Wickham, Pedersen, and Seidel (2023) shape 1.4.6.1 Soetaert (2024) StanHeaders 2.32.9 Stan Development Team (2020) stringi 1.8.4 Gagolewski (2022) svUnit 1.0.6 Grosjean (2024) tensorA 0.36.2.1 van den Boogaart (2023) tidybayes 3.0.6 Kay (2023) tidyselect 1.2.1 Henry and Wickham (2024) tidyverse 2.0.0 H. Wickham et al. (2019) tinytex 0.51 Xie (2019); Xie (2024c) tzdb 0.4.0 Vaughan (2023) ucminf 1.2.1 Nielsen and Mortensen (2023) utf8 1.2.4 Perry (2023) vctrs 0.6.5 H. Wickham, Henry, and Vaughan (2023) viridisLite 0.4.2 Garnier et al. (2023) vroom 1.6.5 Hester, Wickham, and Bryan (2023) withr 3.0.0 Hester et al. (2024) xfun 0.44 Xie (2024d) xtable 1.8.4 Dahl et al. (2019) yaml 2.3.8 Garbett et al. (2023) zoo 1.8.12 Zeileis and Grothendieck (2005) Allaire, JJ, Romain Francois, Kevin Ushey, Gregory Vandenbrouck, Marcus Geelnard, and Intel. 2023. RcppParallel: Parallel Programming Tools for “Rcpp”. https://CRAN.R-project.org/package=RcppParallel. Allaire, JJ, Yihui Xie, Christophe Dervieux, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, et al. 2024. rmarkdown: Dynamic Documents for r. https://github.com/rstudio/rmarkdown. Analytics, Revolution, and Steve Weston. 2022. iterators: Provides Iterator Construct. https://CRAN.R-project.org/package=iterators. Antoine Lucas, Dirk Eddelbuettel with contributions by, Jarek Tuszynski, Henrik Bengtsson, Simon Urbanek, Mario Frasca, Bryan Lewis, Murray Stokely, et al. 2024. digest: Create Compact Hash Digests of r Objects. https://CRAN.R-project.org/package=digest. Arel-Bundock, Vincent, Noah Greifer, and Andrew Heiss. Forthcoming. “How to Interpret Statistical Models Using marginaleffects in R and Python.” Journal of Statistical Software, Forthcoming. Auguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for “Grid” Graphics. https://CRAN.R-project.org/package=gridExtra. Barrett, Tyson, Matt Dowle, Arun Srinivasan, Jan Gorecki, Michael Chirico, and Toby Hocking. 2024. data.table: Extension of “data.frame”. https://CRAN.R-project.org/package=data.table. Bates, Douglas, and Dirk Eddelbuettel. 2013. “Fast and Elegant Numerical Linear Algebra Using the RcppEigen Package.” Journal of Statistical Software 52 (5): 1–24. https://doi.org/10.18637/jss.v052.i05. Bates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015. “Fitting Linear Mixed-Effects Models Using lme4.” Journal of Statistical Software 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01. Bates, Douglas, Katharine M. Mullen, John C. Nash, and Ravi Varadhan. 2024. minqa: Derivative-Free Optimization Algorithms by Quadratic Approximation. https://CRAN.R-project.org/package=minqa. Beleites, C. 2020. arrayhelpers: Convenience Functions for Arrays. https://CRAN.R-project.org/package=arrayhelpers. Bengtsson, Henrik. 2021. “A Unifying Framework for Parallel and Distributed Processing in r Using Futures.” The R Journal 13 (2): 208–27. https://doi.org/10.32614/RJ-2021-048. ———. 2024a. globals: Identify Global Objects in r Expressions. https://CRAN.R-project.org/package=globals. ———. 2024b. listenv: Environments Behaving (Almost) as Lists. https://CRAN.R-project.org/package=listenv. ———. 2024c. matrixStats: Functions That Apply to Rows and Columns of Matrices (and to Vectors). https://CRAN.R-project.org/package=matrixStats. ———. 2024d. parallelly: Enhancing the “parallel” Package. https://CRAN.R-project.org/package=parallelly. Berwin A. Turlach R port by Andreas Weingessel &lt;Andreas.Weingessel@ci.tuwien.ac.at&gt; Fortran contributions from Cleve Moler dpodi/LINPACK), S original by. 2019. quadprog: Functions to Solve Quadratic Programming Problems. https://CRAN.R-project.org/package=quadprog. Bürkner, Paul-Christian. 2017. “brms: An R Package for Bayesian Multilevel Models Using Stan.” Journal of Statistical Software 80 (1): 1–28. https://doi.org/10.18637/jss.v080.i01. ———. 2018. “Advanced Bayesian Multilevel Modeling with the R Package brms.” The R Journal 10 (1): 395–411. https://doi.org/10.32614/RJ-2018-017. ———. 2021. “Bayesian Item Response Modeling in R with brms and Stan.” Journal of Statistical Software 100 (5): 1–54. https://doi.org/10.18637/jss.v100.i05. Bürkner, Paul-Christian, Jonah Gabry, Matthew Kay, and Aki Vehtari. 2023. “posterior: Tools for Working with Posterior Distributions.” https://mc-stan.org/posterior/. Chang, Winston. 2021. R6: Encapsulated Classes with Reference Semantics. https://CRAN.R-project.org/package=R6. ———. 2024a. cachem: Cache r Objects with Automatic Pruning. https://CRAN.R-project.org/package=cachem. ———. 2024b. fastmap: Fast Data Structures. https://CRAN.R-project.org/package=fastmap. Cheng, Joe, Timothy Mastny, Richard Iannone, Barret Schloerke, and Carson Sievert. 2024. sass: Syntactically Awesome Style Sheets (“Sass”). https://CRAN.R-project.org/package=sass. Cheng, Joe, Carson Sievert, Barret Schloerke, Winston Chang, Yihui Xie, and Jeff Allen. 2024. htmltools: Tools for HTML. https://CRAN.R-project.org/package=htmltools. Christensen, Rune H. B. 2023. Ordinal—Regression Models for Ordinal Data. https://CRAN.R-project.org/package=ordinal. Cohen, Jessica, Pascaline Dupas, and Simone Schaner. 2015. “Price Subsidies, Diagnostic Tests, and Targeting of Malaria Treatment: Evidence from a Randomized Controlled Trial.” American Economic Review 105 (2): 609–45. Csardi, Gabor. 2023. prettyunits: Pretty, Human Readable Formatting of Quantities. https://CRAN.R-project.org/package=prettyunits. Csárdi, Gábor. 2019. pkgconfig: Private Configuration for “R” Packages. https://CRAN.R-project.org/package=pkgconfig. ———. 2022. crayon: Colored Terminal Output. https://CRAN.R-project.org/package=crayon. Csárdi, Gábor, and Winston Chang. 2024a. callr: Call r from r. https://CRAN.R-project.org/package=callr. ———. 2024b. processx: Execute and Control System Processes. https://CRAN.R-project.org/package=processx. Csárdi, Gábor, and Rich FitzJohn. 2023. progress: Terminal Progress Bars. https://CRAN.R-project.org/package=progress. Csárdi, Gábor, Jim Hester, Hadley Wickham, Winston Chang, Martin Morgan, and Dan Tenenbaum. 2024. remotes: R Package Installation from Remote Repositories, Including “GitHub”. https://CRAN.R-project.org/package=remotes. Csárdi, Gábor, Kirill Müller, and Jim Hester. 2023. desc: Manipulate DESCRIPTION Files. https://CRAN.R-project.org/package=desc. Dahl, David B., David Scott, Charles Roosen, Arni Magnusson, and Jonathan Swinton. 2019. xtable: Export Tables to LaTeX or HTML. https://CRAN.R-project.org/package=xtable. Eddelbuettel, Dirk. 2013. Seamless R and C++ Integration with Rcpp. New York: Springer. https://doi.org/10.1007/978-1-4614-6868-4. Eddelbuettel, Dirk, and James Joseph Balamuta. 2018. “Extending R with C++: A Brief Introduction to Rcpp.” The American Statistician 72 (1): 28–36. https://doi.org/10.1080/00031305.2017.1375990. Eddelbuettel, Dirk, John W. Emerson, and Michael J. Kane. 2024. BH: Boost c++ Header Files. https://CRAN.R-project.org/package=BH. Eddelbuettel, Dirk, Romain Francois, JJ Allaire, Kevin Ushey, Qiang Kou, Nathan Russell, Inaki Ucar, Douglas Bates, and John Chambers. 2024. Rcpp: Seamless r and c++ Integration. https://CRAN.R-project.org/package=Rcpp. Eddelbuettel, Dirk, and Romain François. 2011. “Rcpp: Seamless R and C++ Integration.” Journal of Statistical Software 40 (8): 1–18. https://doi.org/10.18637/jss.v040.i08. Friedman, Jerome, Robert Tibshirani, and Trevor Hastie. 2010. “Regularization Paths for Generalized Linear Models via Coordinate Descent.” Journal of Statistical Software 33 (1): 1–22. https://doi.org/10.18637/jss.v033.i01. Gabry, Jonah, Ben Goodrich, Martin Lysy, and Andrew Johnson. 2024. rstantools: Tools for Developing r Packages Interfacing with “Stan”. https://CRAN.R-project.org/package=rstantools. Gabry, Jonah, and Tristan Mahr. 2024. “bayesplot: Plotting for Bayesian Models.” https://mc-stan.org/bayesplot/. Gabry, Jonah, Daniel Simpson, Aki Vehtari, Michael Betancourt, and Andrew Gelman. 2019. “Visualization in Bayesian Workflow.” J. R. Stat. Soc. A 182: 389–402. https://doi.org/10.1111/rssa.12378. Gagolewski, Marek. 2022. “stringi: Fast and Portable Character String Processing in R.” Journal of Statistical Software 103 (2): 1–59. https://doi.org/10.18637/jss.v103.i02. Garbett, Shawn P, Jeremy Stephens, Kirill Simonov, Yihui Xie, Zhuoer Dong, Hadley Wickham, Jeffrey Horner, et al. 2023. yaml: Methods to Convert r Data to YAML and Back. https://CRAN.R-project.org/package=yaml. Garnier, Simon, Ross, Noam, Rudis, Robert, Camargo, et al. 2023. viridis(Lite) - Colorblind-Friendly Color Maps for r. https://doi.org/10.5281/zenodo.4678327. Gaslam, Brodie. 2023. fansi: ANSI Control Sequence Aware String Functions. https://CRAN.R-project.org/package=fansi. Genz, Alan, and Frank Bretz. 2009. Computation of Multivariate Normal and t Probabilities. Lecture Notes in Statistics. Heidelberg: Springer-Verlag. Gilbert, Paul, and Ravi Varadhan. 2019. numDeriv: Accurate Numerical Derivatives. https://CRAN.R-project.org/package=numDeriv. Greifer, Noah. 2024. cobalt: Covariate Balance Tables and Plots. https://CRAN.R-project.org/package=cobalt. Gronau, Quentin F., Henrik Singmann, and Eric-Jan Wagenmakers. 2020. “bridgesampling: An R Package for Estimating Normalizing Constants.” Journal of Statistical Software 92 (10): 1–29. https://doi.org/10.18637/jss.v092.i10. Grosjean, Philippe. 2024. SciViews-r. MONS, Belgium: UMONS. https://www.sciviews.org/SciViews-R/. Grund, Simon, Alexander Robitzsch, and Oliver Luedtke. 2023. mitml: Tools for Multiple Imputation in Multilevel Modeling. https://CRAN.R-project.org/package=mitml. Hankin, R. K. S. 2007. “Very Large Numbers in r: Introducing Package Brobdingnag.” R News 7. Hasselman, Berend. 2023. nleqslv: Solve Systems of Nonlinear Equations. https://CRAN.R-project.org/package=nleqslv. Henry, Lionel, and Hadley Wickham. 2023. lifecycle: Manage the Life Cycle of Your Package Functions. https://CRAN.R-project.org/package=lifecycle. ———. 2024. tidyselect: Select from a Set of Strings. https://CRAN.R-project.org/package=tidyselect. Hester, Jim, and Jennifer Bryan. 2024. glue: Interpreted String Literals. https://CRAN.R-project.org/package=glue. Hester, Jim, Lionel Henry, Kirill Müller, Kevin Ushey, Hadley Wickham, and Winston Chang. 2024. withr: Run Code “With” Temporarily Modified Global State. https://CRAN.R-project.org/package=withr. Hester, Jim, Hadley Wickham, and Jennifer Bryan. 2023. vroom: Read and Write Rectangular Text Data Quickly. https://CRAN.R-project.org/package=vroom. Hester, Jim, Hadley Wickham, and Gábor Csárdi. 2024. fs: Cross-Platform File System Operations Based on “libuv”. https://CRAN.R-project.org/package=fs. Huntington-Klein, Nick, and Malcolm Barrett. 2021. causaldata: Example Data Sets for Causal Inference Textbooks. https://CRAN.R-project.org/package=causaldata. Iannone, Richard. 2023. fontawesome: Easily Work with “Font Awesome” Icons. https://CRAN.R-project.org/package=fontawesome. Johnson, Andrew R. 2024. QuickJSR: Interface for the “QuickJS” Lightweight “JavaScript” Engine. https://CRAN.R-project.org/package=QuickJSR. Johnson, Steven G. ? “The NLopt Nonlinear-Optimization Package.” ? ? (?): ? Justin Talbot. 2023. labeling: Axis Labeling. https://CRAN.R-project.org/package=labeling. Kay, Matthew. 2023. tidybayes: Tidy Data and Geoms for Bayesian Models. https://doi.org/10.5281/zenodo.1308151. ———. 2024a. ggdist: Visualizations of Distributions and Uncertainty. https://doi.org/10.5281/zenodo.3879620. ———. 2024b. “ggdist: Visualizations of Distributions and Uncertainty in the Grammar of Graphics.” IEEE Transactions on Visualization and Computer Graphics 30 (1): 414–24. https://doi.org/10.1109/TVCG.2023.3327195. Kurz, A. Solomon. 2023. Statistical Rethinking with Brms, Ggplot2, and the Tidyverse: Second Edition. Version 0.4.0. https://bookdown.org/content/4857/. Lang, Martin, Benjamin G Purzycki, Coren L Apicella, Quentin D Atkinson, Alexander Bolyanatz, Emma Cohen, Carla Handley, et al. 2019. “Moralizing Gods, Impartiality and Religious Parochialism Across 15 Societies.” Proceedings of the Royal Society B 286 (1898): 20190202. Lang, Michel. 2017. “checkmate: Fast Argument Checks for Defensive R Programming.” The R Journal 9 (1): 437–45. https://doi.org/10.32614/RJ-2017-028. Lang, Michel, Duncan Murdoch, and R Core Team. 2024. backports: Reimplementations of Functions Introduced Since r-3.0.0. https://CRAN.R-project.org/package=backports. Lenth, Russell. 2024. estimability: Tools for Assessing Estimability of Linear Predictions. https://CRAN.R-project.org/package=estimability. Lenth, Russell V. 2024. emmeans: Estimated Marginal Means, Aka Least-Squares Means. https://CRAN.R-project.org/package=emmeans. Lincoln, Matthew. 2022. clipr: Read and Write from the System Clipboard. https://CRAN.R-project.org/package=clipr. Loden, Jay, Dave Daeschler, Giampaolo Rodola’, and Gábor Csárdi. 2024. ps: List, Query, Manipulate System Processes. https://CRAN.R-project.org/package=ps. Lüdecke, Daniel, Philip Waggoner, and Dominique Makowski. 2019. “insight: A Unified Interface to Access Information from Model Objects in R.” Journal of Open Source Software 4 (38): 1412. https://doi.org/10.21105/joss.01412. McElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. Second. CRC Press. Microsoft, and Steve Weston. 2022. foreach: Provides Foreach Looping Construct. https://CRAN.R-project.org/package=foreach. Miles, Andrew. 2016. “Obtaining Predictions from Models Fit to Multiply Imputed Data.” Sociological Methods &amp; Research 45 (1): 175–85. https://doi.org/10.1177/0049124115610345. Neuwirth, Erich. 2022. RColorBrewer: ColorBrewer Palettes. https://CRAN.R-project.org/package=RColorBrewer. Nielsen, Hans Bruun, and Stig Bousgaard Mortensen. 2023. ucminf: General-Purpose Unconstrained Non-Linear Optimization. https://CRAN.R-project.org/package=ucminf. O’Hara-Wild, Mitchell, Matthew Kay, and Alex Hayes. 2024. distributional: Vectorised Probability Distributions. https://CRAN.R-project.org/package=distributional. Oehlschlägel, Jens, and Brian Ripley. 2022. bit: Classes and Methods for Fast Memory-Efficient Boolean Selections. https://CRAN.R-project.org/package=bit. Oehlschlägel, Jens, and Leonardo Silvestri. 2020. Bit64: A S3 Class for Vectors of 64bit Integers. https://CRAN.R-project.org/package=bit64. Pedersen, Thomas Lin. 2024. patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork. Pedersen, Thomas Lin, Berendea Nicolae, and Romain François. 2024. farver: High Performance Colour Space Manipulation. https://CRAN.R-project.org/package=farver. Perry, Patrick O. 2023. Utf8: Unicode Text Processing. https://CRAN.R-project.org/package=utf8. Plate, Tony, and Richard Heiberger. 2016. abind: Combine Multidimensional Arrays. https://CRAN.R-project.org/package=abind. Plummer, Martyn, Nicky Best, Kate Cowles, and Karen Vines. 2006. “CODA: Convergence Diagnosis and Output Analysis for MCMC.” R News 6 (1): 7–11. https://journal.r-project.org/archive/. Quartagno, Matteo, and James Carpenter. 2023. jomo: A Package for Multilevel Joint Modelling Multiple Imputation. https://CRAN.R-project.org/package=jomo. R Core Team. 2024. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/. Ratnakumar, Sridhar, Trent Mick, and Trevor Davis. 2021. rappdirs: Application Directories: Determine Where to Save Data, Caches, and Logs. https://CRAN.R-project.org/package=rappdirs. Sievert, Carson, and Joe Cheng. 2021. jquerylib: Obtain “jQuery” as an HTML Dependency Object. https://CRAN.R-project.org/package=jquerylib. Sievert, Carson, Joe Cheng, and Garrick Aden-Buie. 2024. bslib: Custom “Bootstrap” “Sass” Themes for “shiny” and “rmarkdown”. https://CRAN.R-project.org/package=bslib. Simon, Noah, Jerome Friedman, Robert Tibshirani, and Trevor Hastie. 2011. “Regularization Paths for Cox’s Proportional Hazards Model via Coordinate Descent.” Journal of Statistical Software 39 (5): 1–13. https://doi.org/10.18637/jss.v039.i05. Sklyar, Oleg, Duncan Murdoch, Mike Smith, Dirk Eddelbuettel, Romain Francois, Karline Soetaert, and Johannes Ranke. 2021. inline: Functions to Inline c, c++, Fortran Function Calls from r. https://CRAN.R-project.org/package=inline. Soetaert, Karline. 2024. shape: Functions for Plotting Graphical Shapes, Colors. https://CRAN.R-project.org/package=shape. Stan Development Team. 2020. “StanHeaders: Headers for the R Interface to Stan.” https://mc-stan.org/. ———. 2024. “RStan: The R Interface to Stan.” https://mc-stan.org/. Stauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1. Tay, J. Kenneth, Balasubramanian Narasimhan, and Trevor Hastie. 2023. “Elastic Net Regularization Paths for All Generalized Linear Models.” Journal of Statistical Software 106 (1): 1–31. https://doi.org/10.18637/jss.v106.i01. Thorley, Joe, Kirill Müller, and Ayla Pearson. 2023. chk: Check User-Supplied Function Arguments. https://CRAN.R-project.org/package=chk. Urbanek, Simon. 2015. Base64enc: Tools for Base64 Encoding. https://CRAN.R-project.org/package=base64enc. Ushey, Kevin, and Hadley Wickham. 2024. renv: Project Environments. https://CRAN.R-project.org/package=renv. van Buuren, Stef, and Karin Groothuis-Oudshoorn. 2011. “mice: Multivariate Imputation by Chained Equations in r.” Journal of Statistical Software 45 (3): 1–67. https://doi.org/10.18637/jss.v045.i03. van den Boogaart, K. Gerald. 2023. tensorA: Advanced Tensor Arithmetic with Named Indices. https://CRAN.R-project.org/package=tensorA. VanderWeele, Tyler J, John W Jackson, and Shanshan Li. 2016. “Causal Inference and Longitudinal Data: A Case Study of Religion and Mental Health.” Social Psychiatry and Psychiatric Epidemiology 51: 1457–66. Vaughan, Davis. 2023. tzdb: Time Zone Database Information. https://CRAN.R-project.org/package=tzdb. Vaughan, Davis, Jim Hester, and Romain François. 2023. Cpp11: A c++11 Interface for r’s c Interface. https://CRAN.R-project.org/package=cpp11. Vehtari, Aki, Jonah Gabry, Mans Magnusson, Yuling Yao, Paul-Christian Bürkner, Topi Paananen, and Andrew Gelman. 2024. “loo: Efficient Leave-One-Out Cross-Validation and WAIC for Bayesian Models.” https://mc-stan.org/loo/. Vehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017. “Practical Bayesian Model Evaluation Using Leave-One-Out Cross-Validation and WAIC.” Statistics and Computing 27: 1413–32. https://doi.org/10.1007/s11222-016-9696-4. Vehtari, Aki, Andrew Gelman, Daniel Simpson, Bob Carpenter, and Paul-Christian Bürkner. 2021. “Rank-Normalization, Folding, and Localization: An Improved Rhat for Assessing Convergence of MCMC (with Discussion).” Bayesian Analysis. Wickham, Charlotte. 2024. munsell: Utilities for Using Munsell Colours. https://CRAN.R-project.org/package=munsell. Wickham, Hadley. 2007. “Reshaping Data with the reshape Package.” Journal of Statistical Software 21 (12): 1–20. http://www.jstatsoft.org/v21/i12/. ———. 2011. “The Split-Apply-Combine Strategy for Data Analysis.” Journal of Statistical Software 40 (1): 1–29. https://www.jstatsoft.org/v40/i01/. Wickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686. Wickham, Hadley, Lionel Henry, and Davis Vaughan. 2023. vctrs: Vector Helpers. https://CRAN.R-project.org/package=vctrs. Wickham, Hadley, Jim Hester, Winston Chang, Kirill Müller, and Daniel Cook. 2021. memoise: “Memoisation” of Functions. https://CRAN.R-project.org/package=memoise. Wickham, Hadley, Jim Hester, and Gábor Csárdi. 2024. pkgbuild: Find Tools Needed to Build r Packages. https://CRAN.R-project.org/package=pkgbuild. Wickham, Hadley, Max Kuhn, and Davis Vaughan. 2022. generics: Common S3 Generics Not Provided by Base r Methods Related to Model Fitting. https://CRAN.R-project.org/package=generics. Wickham, Hadley, and Thomas Lin Pedersen. 2024. gtable: Arrange “Grobs” in Tables. https://CRAN.R-project.org/package=gtable. Wickham, Hadley, Thomas Lin Pedersen, and Dana Seidel. 2023. scales: Scale Functions for Visualization. https://CRAN.R-project.org/package=scales. Wickham, Hadley, Claus O. Wilke, and Thomas Lin Pedersen. 2022. isoband: Generate Isolines and Isobands from Regularly Spaced Elevation Grids. https://CRAN.R-project.org/package=isoband. Wickham, Hadley, and Yihui Xie. 2023. evaluate: Parsing and Evaluation Tools That Provide More Details Than the Default. https://CRAN.R-project.org/package=evaluate. Wilke, Claus O. 2024. ggridges: Ridgeline Plots in “ggplot2”. https://CRAN.R-project.org/package=ggridges. Xie, Yihui. 2014. “knitr: A Comprehensive Tool for Reproducible Research in R.” In Implementing Reproducible Computational Research, edited by Victoria Stodden, Friedrich Leisch, and Roger D. Peng. Chapman; Hall/CRC. ———. 2015. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. https://yihui.org/knitr/. ———. 2016. bookdown: Authoring Books and Technical Documents with R Markdown. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/bookdown. ———. 2019. “TinyTeX: A Lightweight, Cross-Platform, and Easy-to-Maintain LaTeX Distribution Based on TeX Live.” TUGboat 40 (1): 30–32. https://tug.org/TUGboat/Contents/contents40-1.html. ———. 2021. mime: Map Filenames to MIME Types. https://CRAN.R-project.org/package=mime. ———. 2024a. bookdown: Authoring Books and Technical Documents with r Markdown. https://github.com/rstudio/bookdown. ———. 2024b. knitr: A General-Purpose Package for Dynamic Report Generation in r. https://yihui.org/knitr/. ———. 2024c. tinytex: Helper Functions to Install and Maintain TeX Live, and Compile LaTeX Documents. https://github.com/rstudio/tinytex. ———. 2024d. xfun: Supporting Functions for Packages Maintained by “Yihui Xie”. https://CRAN.R-project.org/package=xfun. Xie, Yihui, J. J. Allaire, and Garrett Grolemund. 2018. R Markdown: The Definitive Guide. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown. Xie, Yihui, Christophe Dervieux, and Emily Riederer. 2020. R Markdown Cookbook. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown-cookbook. Xie, Yihui, and Yixuan Qiu. 2024. highr: Syntax Highlighting for r Source Code. https://CRAN.R-project.org/package=highr. Yao, Yuling, Aki Vehtari, Daniel Simpson, and Andrew Gelman. 2017. “Using Stacking to Average Bayesian Predictive Distributions.” Bayesian Analysis. https://doi.org/10.1214/17-BA1091. Zeileis, Achim. 2004. “Econometric Computing with HC and HAC Covariance Matrix Estimators.” Journal of Statistical Software 11 (10): 1–17. https://doi.org/10.18637/jss.v011.i10. ———. 2006. “Object-Oriented Computation of Sandwich Estimators.” Journal of Statistical Software 16 (9): 1–16. https://doi.org/10.18637/jss.v016.i09. Zeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01. Zeileis, Achim, and Gabor Grothendieck. 2005. “zoo: S3 Infrastructure for Regular and Irregular Time Series.” Journal of Statistical Software 14 (6): 1–27. https://doi.org/10.18637/jss.v014.i06. Zeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics &amp; Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033. Zeileis, Achim, Susanne Köll, and Nathaniel Graham. 2020. “Various Versatile Variances: An Object-Oriented Implementation of Clustered Covariances in R.” Journal of Statistical Software 95 (1): 1–36. https://doi.org/10.18637/jss.v095.i01. Zhao, Jing Hua, and Joseph L. Schafer. 2023. pan: Multiple Imputation for Multivariate Panel or Clustered Data. References Allaire, JJ, Romain Francois, Kevin Ushey, Gregory Vandenbrouck, Marcus Geelnard, and Intel. 2023. RcppParallel: Parallel Programming Tools for “Rcpp”. https://CRAN.R-project.org/package=RcppParallel. Allaire, JJ, Yihui Xie, Christophe Dervieux, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, et al. 2024. rmarkdown: Dynamic Documents for r. https://github.com/rstudio/rmarkdown. Analytics, Revolution, and Steve Weston. 2022. iterators: Provides Iterator Construct. https://CRAN.R-project.org/package=iterators. Antoine Lucas, Dirk Eddelbuettel with contributions by, Jarek Tuszynski, Henrik Bengtsson, Simon Urbanek, Mario Frasca, Bryan Lewis, Murray Stokely, et al. 2024. digest: Create Compact Hash Digests of r Objects. https://CRAN.R-project.org/package=digest. Arel-Bundock, Vincent, Noah Greifer, and Andrew Heiss. Forthcoming. “How to Interpret Statistical Models Using marginaleffects in R and Python.” Journal of Statistical Software, Forthcoming. Auguie, Baptiste. 2017. gridExtra: Miscellaneous Functions for “Grid” Graphics. https://CRAN.R-project.org/package=gridExtra. Barrett, Tyson, Matt Dowle, Arun Srinivasan, Jan Gorecki, Michael Chirico, and Toby Hocking. 2024. data.table: Extension of “data.frame”. https://CRAN.R-project.org/package=data.table. Bates, Douglas, and Dirk Eddelbuettel. 2013. “Fast and Elegant Numerical Linear Algebra Using the RcppEigen Package.” Journal of Statistical Software 52 (5): 1–24. https://doi.org/10.18637/jss.v052.i05. Bates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015. “Fitting Linear Mixed-Effects Models Using lme4.” Journal of Statistical Software 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01. Bates, Douglas, Katharine M. Mullen, John C. Nash, and Ravi Varadhan. 2024. minqa: Derivative-Free Optimization Algorithms by Quadratic Approximation. https://CRAN.R-project.org/package=minqa. Beleites, C. 2020. arrayhelpers: Convenience Functions for Arrays. https://CRAN.R-project.org/package=arrayhelpers. Bengtsson, Henrik. 2021. “A Unifying Framework for Parallel and Distributed Processing in r Using Futures.” The R Journal 13 (2): 208–27. https://doi.org/10.32614/RJ-2021-048. ———. 2024a. globals: Identify Global Objects in r Expressions. https://CRAN.R-project.org/package=globals. ———. 2024b. listenv: Environments Behaving (Almost) as Lists. https://CRAN.R-project.org/package=listenv. ———. 2024c. matrixStats: Functions That Apply to Rows and Columns of Matrices (and to Vectors). https://CRAN.R-project.org/package=matrixStats. ———. 2024d. parallelly: Enhancing the “parallel” Package. https://CRAN.R-project.org/package=parallelly. Berwin A. Turlach R port by Andreas Weingessel &lt;Andreas.Weingessel@ci.tuwien.ac.at&gt; Fortran contributions from Cleve Moler dpodi/LINPACK), S original by. 2019. quadprog: Functions to Solve Quadratic Programming Problems. https://CRAN.R-project.org/package=quadprog. Bürkner, Paul-Christian. 2017. “brms: An R Package for Bayesian Multilevel Models Using Stan.” Journal of Statistical Software 80 (1): 1–28. https://doi.org/10.18637/jss.v080.i01. ———. 2018. “Advanced Bayesian Multilevel Modeling with the R Package brms.” The R Journal 10 (1): 395–411. https://doi.org/10.32614/RJ-2018-017. ———. 2021. “Bayesian Item Response Modeling in R with brms and Stan.” Journal of Statistical Software 100 (5): 1–54. https://doi.org/10.18637/jss.v100.i05. Bürkner, Paul-Christian, Jonah Gabry, Matthew Kay, and Aki Vehtari. 2023. “posterior: Tools for Working with Posterior Distributions.” https://mc-stan.org/posterior/. Chang, Winston. 2021. R6: Encapsulated Classes with Reference Semantics. https://CRAN.R-project.org/package=R6. ———. 2024a. cachem: Cache r Objects with Automatic Pruning. https://CRAN.R-project.org/package=cachem. ———. 2024b. fastmap: Fast Data Structures. https://CRAN.R-project.org/package=fastmap. Cheng, Joe, Timothy Mastny, Richard Iannone, Barret Schloerke, and Carson Sievert. 2024. sass: Syntactically Awesome Style Sheets (“Sass”). https://CRAN.R-project.org/package=sass. Cheng, Joe, Carson Sievert, Barret Schloerke, Winston Chang, Yihui Xie, and Jeff Allen. 2024. htmltools: Tools for HTML. https://CRAN.R-project.org/package=htmltools. Christensen, Rune H. B. 2023. Ordinal—Regression Models for Ordinal Data. https://CRAN.R-project.org/package=ordinal. Csardi, Gabor. 2023. prettyunits: Pretty, Human Readable Formatting of Quantities. https://CRAN.R-project.org/package=prettyunits. Csárdi, Gábor. 2019. pkgconfig: Private Configuration for “R” Packages. https://CRAN.R-project.org/package=pkgconfig. ———. 2022. crayon: Colored Terminal Output. https://CRAN.R-project.org/package=crayon. Csárdi, Gábor, and Winston Chang. 2024a. callr: Call r from r. https://CRAN.R-project.org/package=callr. ———. 2024b. processx: Execute and Control System Processes. https://CRAN.R-project.org/package=processx. Csárdi, Gábor, and Rich FitzJohn. 2023. progress: Terminal Progress Bars. https://CRAN.R-project.org/package=progress. Csárdi, Gábor, Jim Hester, Hadley Wickham, Winston Chang, Martin Morgan, and Dan Tenenbaum. 2024. remotes: R Package Installation from Remote Repositories, Including “GitHub”. https://CRAN.R-project.org/package=remotes. Csárdi, Gábor, Kirill Müller, and Jim Hester. 2023. desc: Manipulate DESCRIPTION Files. https://CRAN.R-project.org/package=desc. Dahl, David B., David Scott, Charles Roosen, Arni Magnusson, and Jonathan Swinton. 2019. xtable: Export Tables to LaTeX or HTML. https://CRAN.R-project.org/package=xtable. Eddelbuettel, Dirk. 2013. Seamless R and C++ Integration with Rcpp. New York: Springer. https://doi.org/10.1007/978-1-4614-6868-4. Eddelbuettel, Dirk, and James Joseph Balamuta. 2018. “Extending R with C++: A Brief Introduction to Rcpp.” The American Statistician 72 (1): 28–36. https://doi.org/10.1080/00031305.2017.1375990. Eddelbuettel, Dirk, John W. Emerson, and Michael J. Kane. 2024. BH: Boost c++ Header Files. https://CRAN.R-project.org/package=BH. Eddelbuettel, Dirk, Romain Francois, JJ Allaire, Kevin Ushey, Qiang Kou, Nathan Russell, Inaki Ucar, Douglas Bates, and John Chambers. 2024. Rcpp: Seamless r and c++ Integration. https://CRAN.R-project.org/package=Rcpp. Eddelbuettel, Dirk, and Romain François. 2011. “Rcpp: Seamless R and C++ Integration.” Journal of Statistical Software 40 (8): 1–18. https://doi.org/10.18637/jss.v040.i08. Friedman, Jerome, Robert Tibshirani, and Trevor Hastie. 2010. “Regularization Paths for Generalized Linear Models via Coordinate Descent.” Journal of Statistical Software 33 (1): 1–22. https://doi.org/10.18637/jss.v033.i01. Gabry, Jonah, Ben Goodrich, Martin Lysy, and Andrew Johnson. 2024. rstantools: Tools for Developing r Packages Interfacing with “Stan”. https://CRAN.R-project.org/package=rstantools. Gabry, Jonah, and Tristan Mahr. 2024. “bayesplot: Plotting for Bayesian Models.” https://mc-stan.org/bayesplot/. Gabry, Jonah, Daniel Simpson, Aki Vehtari, Michael Betancourt, and Andrew Gelman. 2019. “Visualization in Bayesian Workflow.” J. R. Stat. Soc. A 182: 389–402. https://doi.org/10.1111/rssa.12378. Gagolewski, Marek. 2022. “stringi: Fast and Portable Character String Processing in R.” Journal of Statistical Software 103 (2): 1–59. https://doi.org/10.18637/jss.v103.i02. Garbett, Shawn P, Jeremy Stephens, Kirill Simonov, Yihui Xie, Zhuoer Dong, Hadley Wickham, Jeffrey Horner, et al. 2023. yaml: Methods to Convert r Data to YAML and Back. https://CRAN.R-project.org/package=yaml. Garnier, Simon, Ross, Noam, Rudis, Robert, Camargo, et al. 2023. viridis(Lite) - Colorblind-Friendly Color Maps for r. https://doi.org/10.5281/zenodo.4678327. Gaslam, Brodie. 2023. fansi: ANSI Control Sequence Aware String Functions. https://CRAN.R-project.org/package=fansi. Genz, Alan, and Frank Bretz. 2009. Computation of Multivariate Normal and t Probabilities. Lecture Notes in Statistics. Heidelberg: Springer-Verlag. Gilbert, Paul, and Ravi Varadhan. 2019. numDeriv: Accurate Numerical Derivatives. https://CRAN.R-project.org/package=numDeriv. Greifer, Noah. 2024. cobalt: Covariate Balance Tables and Plots. https://CRAN.R-project.org/package=cobalt. Gronau, Quentin F., Henrik Singmann, and Eric-Jan Wagenmakers. 2020. “bridgesampling: An R Package for Estimating Normalizing Constants.” Journal of Statistical Software 92 (10): 1–29. https://doi.org/10.18637/jss.v092.i10. Grosjean, Philippe. 2024. SciViews-r. MONS, Belgium: UMONS. https://www.sciviews.org/SciViews-R/. Grund, Simon, Alexander Robitzsch, and Oliver Luedtke. 2023. mitml: Tools for Multiple Imputation in Multilevel Modeling. https://CRAN.R-project.org/package=mitml. Hankin, R. K. S. 2007. “Very Large Numbers in r: Introducing Package Brobdingnag.” R News 7. Hasselman, Berend. 2023. nleqslv: Solve Systems of Nonlinear Equations. https://CRAN.R-project.org/package=nleqslv. Henry, Lionel, and Hadley Wickham. 2023. lifecycle: Manage the Life Cycle of Your Package Functions. https://CRAN.R-project.org/package=lifecycle. ———. 2024. tidyselect: Select from a Set of Strings. https://CRAN.R-project.org/package=tidyselect. Hester, Jim, and Jennifer Bryan. 2024. glue: Interpreted String Literals. https://CRAN.R-project.org/package=glue. Hester, Jim, Lionel Henry, Kirill Müller, Kevin Ushey, Hadley Wickham, and Winston Chang. 2024. withr: Run Code “With” Temporarily Modified Global State. https://CRAN.R-project.org/package=withr. Hester, Jim, Hadley Wickham, and Jennifer Bryan. 2023. vroom: Read and Write Rectangular Text Data Quickly. https://CRAN.R-project.org/package=vroom. Hester, Jim, Hadley Wickham, and Gábor Csárdi. 2024. fs: Cross-Platform File System Operations Based on “libuv”. https://CRAN.R-project.org/package=fs. Huntington-Klein, Nick, and Malcolm Barrett. 2021. causaldata: Example Data Sets for Causal Inference Textbooks. https://CRAN.R-project.org/package=causaldata. Iannone, Richard. 2023. fontawesome: Easily Work with “Font Awesome” Icons. https://CRAN.R-project.org/package=fontawesome. Johnson, Andrew R. 2024. QuickJSR: Interface for the “QuickJS” Lightweight “JavaScript” Engine. https://CRAN.R-project.org/package=QuickJSR. Johnson, Steven G. ? “The NLopt Nonlinear-Optimization Package.” ? ? (?): ? Justin Talbot. 2023. labeling: Axis Labeling. https://CRAN.R-project.org/package=labeling. Kay, Matthew. 2023. tidybayes: Tidy Data and Geoms for Bayesian Models. https://doi.org/10.5281/zenodo.1308151. ———. 2024a. ggdist: Visualizations of Distributions and Uncertainty. https://doi.org/10.5281/zenodo.3879620. ———. 2024b. “ggdist: Visualizations of Distributions and Uncertainty in the Grammar of Graphics.” IEEE Transactions on Visualization and Computer Graphics 30 (1): 414–24. https://doi.org/10.1109/TVCG.2023.3327195. Lang, Michel. 2017. “checkmate: Fast Argument Checks for Defensive R Programming.” The R Journal 9 (1): 437–45. https://doi.org/10.32614/RJ-2017-028. Lang, Michel, Duncan Murdoch, and R Core Team. 2024. backports: Reimplementations of Functions Introduced Since r-3.0.0. https://CRAN.R-project.org/package=backports. Lenth, Russell. 2024. estimability: Tools for Assessing Estimability of Linear Predictions. https://CRAN.R-project.org/package=estimability. Lenth, Russell V. 2024. emmeans: Estimated Marginal Means, Aka Least-Squares Means. https://CRAN.R-project.org/package=emmeans. Lincoln, Matthew. 2022. clipr: Read and Write from the System Clipboard. https://CRAN.R-project.org/package=clipr. Loden, Jay, Dave Daeschler, Giampaolo Rodola’, and Gábor Csárdi. 2024. ps: List, Query, Manipulate System Processes. https://CRAN.R-project.org/package=ps. Lüdecke, Daniel, Philip Waggoner, and Dominique Makowski. 2019. “insight: A Unified Interface to Access Information from Model Objects in R.” Journal of Open Source Software 4 (38): 1412. https://doi.org/10.21105/joss.01412. Microsoft, and Steve Weston. 2022. foreach: Provides Foreach Looping Construct. https://CRAN.R-project.org/package=foreach. Neuwirth, Erich. 2022. RColorBrewer: ColorBrewer Palettes. https://CRAN.R-project.org/package=RColorBrewer. Nielsen, Hans Bruun, and Stig Bousgaard Mortensen. 2023. ucminf: General-Purpose Unconstrained Non-Linear Optimization. https://CRAN.R-project.org/package=ucminf. O’Hara-Wild, Mitchell, Matthew Kay, and Alex Hayes. 2024. distributional: Vectorised Probability Distributions. https://CRAN.R-project.org/package=distributional. Oehlschlägel, Jens, and Brian Ripley. 2022. bit: Classes and Methods for Fast Memory-Efficient Boolean Selections. https://CRAN.R-project.org/package=bit. Oehlschlägel, Jens, and Leonardo Silvestri. 2020. Bit64: A S3 Class for Vectors of 64bit Integers. https://CRAN.R-project.org/package=bit64. Pedersen, Thomas Lin. 2024. patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork. Pedersen, Thomas Lin, Berendea Nicolae, and Romain François. 2024. farver: High Performance Colour Space Manipulation. https://CRAN.R-project.org/package=farver. Perry, Patrick O. 2023. Utf8: Unicode Text Processing. https://CRAN.R-project.org/package=utf8. Plate, Tony, and Richard Heiberger. 2016. abind: Combine Multidimensional Arrays. https://CRAN.R-project.org/package=abind. Plummer, Martyn, Nicky Best, Kate Cowles, and Karen Vines. 2006. “CODA: Convergence Diagnosis and Output Analysis for MCMC.” R News 6 (1): 7–11. https://journal.r-project.org/archive/. Quartagno, Matteo, and James Carpenter. 2023. jomo: A Package for Multilevel Joint Modelling Multiple Imputation. https://CRAN.R-project.org/package=jomo. R Core Team. 2024. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/. Ratnakumar, Sridhar, Trent Mick, and Trevor Davis. 2021. rappdirs: Application Directories: Determine Where to Save Data, Caches, and Logs. https://CRAN.R-project.org/package=rappdirs. Sievert, Carson, and Joe Cheng. 2021. jquerylib: Obtain “jQuery” as an HTML Dependency Object. https://CRAN.R-project.org/package=jquerylib. Sievert, Carson, Joe Cheng, and Garrick Aden-Buie. 2024. bslib: Custom “Bootstrap” “Sass” Themes for “shiny” and “rmarkdown”. https://CRAN.R-project.org/package=bslib. Simon, Noah, Jerome Friedman, Robert Tibshirani, and Trevor Hastie. 2011. “Regularization Paths for Cox’s Proportional Hazards Model via Coordinate Descent.” Journal of Statistical Software 39 (5): 1–13. https://doi.org/10.18637/jss.v039.i05. Sklyar, Oleg, Duncan Murdoch, Mike Smith, Dirk Eddelbuettel, Romain Francois, Karline Soetaert, and Johannes Ranke. 2021. inline: Functions to Inline c, c++, Fortran Function Calls from r. https://CRAN.R-project.org/package=inline. Soetaert, Karline. 2024. shape: Functions for Plotting Graphical Shapes, Colors. https://CRAN.R-project.org/package=shape. Stan Development Team. 2020. “StanHeaders: Headers for the R Interface to Stan.” https://mc-stan.org/. ———. 2024. “RStan: The R Interface to Stan.” https://mc-stan.org/. Stauffer, Reto, Georg J. Mayr, Markus Dabernig, and Achim Zeileis. 2009. “Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations.” Bulletin of the American Meteorological Society 96 (2): 203–16. https://doi.org/10.1175/BAMS-D-13-00155.1. Tay, J. Kenneth, Balasubramanian Narasimhan, and Trevor Hastie. 2023. “Elastic Net Regularization Paths for All Generalized Linear Models.” Journal of Statistical Software 106 (1): 1–31. https://doi.org/10.18637/jss.v106.i01. Thorley, Joe, Kirill Müller, and Ayla Pearson. 2023. chk: Check User-Supplied Function Arguments. https://CRAN.R-project.org/package=chk. Urbanek, Simon. 2015. Base64enc: Tools for Base64 Encoding. https://CRAN.R-project.org/package=base64enc. Ushey, Kevin, and Hadley Wickham. 2024. renv: Project Environments. https://CRAN.R-project.org/package=renv. van Buuren, Stef, and Karin Groothuis-Oudshoorn. 2011. “mice: Multivariate Imputation by Chained Equations in r.” Journal of Statistical Software 45 (3): 1–67. https://doi.org/10.18637/jss.v045.i03. van den Boogaart, K. Gerald. 2023. tensorA: Advanced Tensor Arithmetic with Named Indices. https://CRAN.R-project.org/package=tensorA. Vaughan, Davis. 2023. tzdb: Time Zone Database Information. https://CRAN.R-project.org/package=tzdb. Vaughan, Davis, Jim Hester, and Romain François. 2023. Cpp11: A c++11 Interface for r’s c Interface. https://CRAN.R-project.org/package=cpp11. Vehtari, Aki, Jonah Gabry, Mans Magnusson, Yuling Yao, Paul-Christian Bürkner, Topi Paananen, and Andrew Gelman. 2024. “loo: Efficient Leave-One-Out Cross-Validation and WAIC for Bayesian Models.” https://mc-stan.org/loo/. Vehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017. “Practical Bayesian Model Evaluation Using Leave-One-Out Cross-Validation and WAIC.” Statistics and Computing 27: 1413–32. https://doi.org/10.1007/s11222-016-9696-4. Vehtari, Aki, Andrew Gelman, Daniel Simpson, Bob Carpenter, and Paul-Christian Bürkner. 2021. “Rank-Normalization, Folding, and Localization: An Improved Rhat for Assessing Convergence of MCMC (with Discussion).” Bayesian Analysis. Wickham, Charlotte. 2024. munsell: Utilities for Using Munsell Colours. https://CRAN.R-project.org/package=munsell. Wickham, Hadley. 2007. “Reshaping Data with the reshape Package.” Journal of Statistical Software 21 (12): 1–20. http://www.jstatsoft.org/v21/i12/. ———. 2011. “The Split-Apply-Combine Strategy for Data Analysis.” Journal of Statistical Software 40 (1): 1–29. https://www.jstatsoft.org/v40/i01/. Wickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686. Wickham, Hadley, Lionel Henry, and Davis Vaughan. 2023. vctrs: Vector Helpers. https://CRAN.R-project.org/package=vctrs. Wickham, Hadley, Jim Hester, Winston Chang, Kirill Müller, and Daniel Cook. 2021. memoise: “Memoisation” of Functions. https://CRAN.R-project.org/package=memoise. Wickham, Hadley, Jim Hester, and Gábor Csárdi. 2024. pkgbuild: Find Tools Needed to Build r Packages. https://CRAN.R-project.org/package=pkgbuild. Wickham, Hadley, Max Kuhn, and Davis Vaughan. 2022. generics: Common S3 Generics Not Provided by Base r Methods Related to Model Fitting. https://CRAN.R-project.org/package=generics. Wickham, Hadley, and Thomas Lin Pedersen. 2024. gtable: Arrange “Grobs” in Tables. https://CRAN.R-project.org/package=gtable. Wickham, Hadley, Thomas Lin Pedersen, and Dana Seidel. 2023. scales: Scale Functions for Visualization. https://CRAN.R-project.org/package=scales. Wickham, Hadley, Claus O. Wilke, and Thomas Lin Pedersen. 2022. isoband: Generate Isolines and Isobands from Regularly Spaced Elevation Grids. https://CRAN.R-project.org/package=isoband. Wickham, Hadley, and Yihui Xie. 2023. evaluate: Parsing and Evaluation Tools That Provide More Details Than the Default. https://CRAN.R-project.org/package=evaluate. Wilke, Claus O. 2024. ggridges: Ridgeline Plots in “ggplot2”. https://CRAN.R-project.org/package=ggridges. Xie, Yihui. 2014. “knitr: A Comprehensive Tool for Reproducible Research in R.” In Implementing Reproducible Computational Research, edited by Victoria Stodden, Friedrich Leisch, and Roger D. Peng. Chapman; Hall/CRC. ———. 2015. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. https://yihui.org/knitr/. ———. 2016. bookdown: Authoring Books and Technical Documents with R Markdown. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/bookdown. ———. 2019. “TinyTeX: A Lightweight, Cross-Platform, and Easy-to-Maintain LaTeX Distribution Based on TeX Live.” TUGboat 40 (1): 30–32. https://tug.org/TUGboat/Contents/contents40-1.html. ———. 2021. mime: Map Filenames to MIME Types. https://CRAN.R-project.org/package=mime. ———. 2024a. bookdown: Authoring Books and Technical Documents with r Markdown. https://github.com/rstudio/bookdown. ———. 2024b. knitr: A General-Purpose Package for Dynamic Report Generation in r. https://yihui.org/knitr/. ———. 2024c. tinytex: Helper Functions to Install and Maintain TeX Live, and Compile LaTeX Documents. https://github.com/rstudio/tinytex. ———. 2024d. xfun: Supporting Functions for Packages Maintained by “Yihui Xie”. https://CRAN.R-project.org/package=xfun. Xie, Yihui, J. J. Allaire, and Garrett Grolemund. 2018. R Markdown: The Definitive Guide. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown. Xie, Yihui, Christophe Dervieux, and Emily Riederer. 2020. R Markdown Cookbook. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown-cookbook. Xie, Yihui, and Yixuan Qiu. 2024. highr: Syntax Highlighting for r Source Code. https://CRAN.R-project.org/package=highr. Yao, Yuling, Aki Vehtari, Daniel Simpson, and Andrew Gelman. 2017. “Using Stacking to Average Bayesian Predictive Distributions.” Bayesian Analysis. https://doi.org/10.1214/17-BA1091. Zeileis, Achim. 2004. “Econometric Computing with HC and HAC Covariance Matrix Estimators.” Journal of Statistical Software 11 (10): 1–17. https://doi.org/10.18637/jss.v011.i10. ———. 2006. “Object-Oriented Computation of Sandwich Estimators.” Journal of Statistical Software 16 (9): 1–16. https://doi.org/10.18637/jss.v016.i09. Zeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01. Zeileis, Achim, and Gabor Grothendieck. 2005. “zoo: S3 Infrastructure for Regular and Irregular Time Series.” Journal of Statistical Software 14 (6): 1–27. https://doi.org/10.18637/jss.v014.i06. Zeileis, Achim, Kurt Hornik, and Paul Murrell. 2009. “Escaping RGBland: Selecting Colors for Statistical Graphics.” Computational Statistics &amp; Data Analysis 53 (9): 3259–70. https://doi.org/10.1016/j.csda.2008.11.033. Zeileis, Achim, Susanne Köll, and Nathaniel Graham. 2020. “Various Versatile Variances: An Object-Oriented Implementation of Clustered Covariances in R.” Journal of Statistical Software 95 (1): 1–36. https://doi.org/10.18637/jss.v095.i01. Zhao, Jing Hua, and Joseph L. Schafer. 2023. pan: Multiple Imputation for Multivariate Panel or Clustered Data. "]]
