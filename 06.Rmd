# More Missing Data {#chapter-6}

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      results = 'hide', 
                      cache = FALSE, 
                      warning = FALSE,
                      message = FALSE,
                      error = TRUE,
                      cache.comments = FALSE,
                      cache.lazy = FALSE,
                      fig.path = "bookdown-dag_files/figure-html/ch6-fig-",
                      cache.path = "bookdown-dag_cache/html/ch6-")

```

## Simple mean imputation vs. multiple imputation

Here we illustrate simple mean imputation.

```{r, results='markup'}
d <- read.csv("data/cohen2015miss.csv")

d$age <- scale(d$age) |> as.numeric()
d_mimp <- d
d_mimp$age <- with(d_mimp,
                   ifelse(is.na(age),
                          mean(age, na.rm = T),
                          age))

lm(act ~ subsidy + age, data = d_mimp) |> summary()
```

We can compare with a complete-case analysis...

```{r, results='markup'}
lm(act ~ subsidy + age, data = d) |> summary()
```

... As well as multiple imputation.

```{r}
library(mice)
set.seed(1)

imp <- mice(d)
```

```{r, results='markup'}
fit <- with(imp, lm(act ~ subsidy + age))

pool(fit) |> summary()
```

In all cases, the point estimate for both the intercept and effect of subsidy is around 0.20.

## "Combine then predict" or "predict then combine"?

In the main text we say that we have a choice to make when working with a model fitted on multiply imputed data: Do we apply Rubin's pooling rules on the model coefficients or on model predictions? We can refer to these different approaches as "combine then predict" and "predict then combine," respectively, following @miles2016.

Since different `R` packages implement post-processing of multiply imputed model fits differently, we show a basic implementations here with two popular `R` packages. What the packages have in common is that they allow us to conveniently work with the `mice` object as we would any other model fit. Let's proceed with the malaria subsidy data and imagine we want an average treatment effect of the subsidy treatment of ACT uptake marginal of age using g-computation.

### `marginaleffects`

The `marginaleffects` package [@marginaleffects] implements "predict then combine"; that is, it obtains model predictions for each of the *m* data sets and then apply Rubin's rules to the predictions to pool them. G-computation is very straightforward to implement.

```{r, results='markup'}
library(marginaleffects)

avg_comparisons(fit, variables = list(subsidy = 0:1))
```

### `emmeans`

On the other hand, the `emmeans` package [@emmeans] implements "combine then predict"; that is, it applies Rubin's rules to the model coefficients to pool them and only then obtain model predictions. A basic g-computation implementation could like this using `emmeans`.

```{r, results='markup'}
library(emmeans)

emmeans(specs = "subsidy", 
        ref_grid(fit)) |>
  contrast("revpairwise") |>
  confint()
```

We see that results are identical to those obtained with `marginaleffects`.

### Comparison

But let's try to see when the two different approaches give different results. Instead of a linear model on the imputed datasets, we instead use a non-linear model in the form of a logistic regression. We do this by calling `glm()` instead of `lm()` and setting `family = "binomial"`.

```{r}
fit_binom <- with(imp, glm(act ~ subsidy + age, family = "binomial"))
```

Then, we apply our two approaches. The `marginaleffects` implementation is identical to above even though the model fit is now a logistic regression.

```{r, results='markup'}
avg_comparisons(fit_binom, variables = list(subsidy = 0:1))
```

For the `emmeans` approach, to get predictions on the probability scale, we can wrap the `ref_grid()` function in `regrid()` and set `type = "response"`. We see that results are very similar but not identical.

```{r, results='markup'}
emmeans(specs = "subsidy",
        regrid(ref_grid(fit_binom),
        type = "response")) |>
  contrast("revpairwise") |>
  confint()
```

## Bayesian imputation

In the book, we also mentioned an alternative imputation approach, namely Bayesian imputation. Using the `brms` package [@brms2017; @brms2018; @brms2021], we'll show a very basic implementation. The syntax should seem somewhat familiar, as `brms` uses common `R` regression syntax.

First, we define the model formula. At its core, it's similar to the `lm()` formula above, except for a few complications. The formula object holds two main components, each wrapped by `bf()`. In the first part, we indicate the covariate we want to impute -- in the case, `age` -- with the `mi()` wrapper. The second part specifies a model for the variable we want to impute. Finally, we feed that formula to `brm()` along with the data. We then set the cores to 4 for speedier sampling and a seed for numeric reproducibility. We strongly recommend McElreath (and Kurz' translations) [REF] for more details and a general introduction ot Bayesian inference more generally. 

```{r}
library(brms)
```

```{r, eval=FALSE}
# Define model formula
formula <- bf(act ~ subsidy + mi(age)) +
           bf(age | mi() ~ 1)

# Fit model to data
bfit <- brm(formula,
            data = d,
            cores = 4, seed = 2020,
            file = "fits/bfit.rds")

```

```{r bfit, cache=TRUE, echo=FALSE}
bfit <- readRDS("fits/bfit.rds")
```

We can get a summary of the Bayesian model by calling `summary()`

```{r, results='markup'}
summary(bfit)
```

The coefficient `act_subsidy` corresponds to the `subsidy` coefficient in the `lm()` and `glm()` calls above. We see that the coefficients are very similar to the models above, except now we also have coefficients for the model predicting age (the `age_` parameters).

Now, there are many ways to extend this model, which are outside the scope of this companion website, for instance using more informative prior settings, constraining imputed values to be within realistic ranges, include covariates in the sub-model predicting missing `age` values, or use a different likelihood for `act` that respects its binary nature (e.g., a logistic regression model).

We can also inspect the distribution of imputed values. For instance, we can plot 20 draws from the distribution of the imputed age variable (light blue curves) against the observed distribution of age in the sample (dark blue curve)... 

```{r, fig.width=5, fig.height=3}
pp_check(bfit, resp = "age", ndraws = 20)
```

... Which is somewhat similar to this plot of imputed data sets (red curves) against the observed (blue curve) from the `mice` implementation shown in the text.

```{r, fig.width=5, fig.height=3}
densityplot(imp, ~ age)
```

Now, we can post-process the Bayesian model fit exactly as shown in Chapters 3 and 5 [REF] using the `tidybayes`-based workflow [@tidybayes]. Or, we can use `marginaleffects` just as shown for the `mice` object above, except we need to specify that it's the model predicting ACT uptake that we want to apply g-computation to; this is what `resp = "act"` does.

```{r, results='markup'}
avg_comparisons(bfit, variables = list(subsidy = 0:1), resp = "act")
```

## Session info

```{r, results='markup'}
sessionInfo()
```
